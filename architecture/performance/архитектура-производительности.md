---
aliases: ["Performance Architecture", "Performance Optimization", "Performance Testing", "Performance Monitoring", "Архитектура производительности", "Оптимизация производительности"]
tags: ["#performance", "#architecture", "#optimization", "#testing", "#monitoring", "#scalability", "#ci-cd", "#frontend", "#backend", "#microservices", "#eda"]
---

# Unified Performance Architecture: Комплексное руководство по архитектуре производительности

## Введение в Performance Architecture

Performance Architecture - это архитектурный подход, фокусирующийся на создании систем, оптимизированных для высокой производительности, масштабируемости и надежности. Она охватывает все аспекты разработки программного обеспечения: от проектирования архитектуры до мониторинга в продакшене.

Performance Architecture включает в себя:
- Проектирование высокопроизводительных систем
- Оптимизацию алгоритмов и структур данных
- Эффективное использование ресурсов
- Тестирование производительности
- Мониторинг и наблюдаемость
- Оптимизацию в контексте CI/CD

## Основные компоненты Performance Architecture

### 1. Проектирование для производительности

При проектировании архитектуры системы необходимо учитывать производительность как ключевое требование:

```javascript
// Пример архитектуры с учетом производительности
class PerformanceOptimizedService {
  constructor(config) {
    this.config = config;
    this.cache = new LRUCache(config.cacheSize || 1000);
    this.rateLimiter = new TokenBucketLimiter(config.rateLimit || 100);
    this.connectionPool = new ConnectionPool(config.dbConfig);
    this.metrics = new MetricsCollector();
  }

  async performOperation(data) {
    // Использование кэширования для уменьшения времени отклика
    const cacheKey = this.generateCacheKey(data);
    const cachedResult = this.cache.get(cacheKey);
    
    if (cachedResult) {
      this.metrics.increment('cache_hit');
      return cachedResult;
    }

    // Проверка лимита запросов
    if (!this.rateLimiter.consume()) {
      throw new Error('Rate limit exceeded');
    }

    // Выполнение операции с измерением производительности
    const startTime = Date.now();
    const result = await this.executeOperation(data);
    const duration = Date.now() - startTime;

    this.metrics.histogram('operation_duration', duration);
    
    // Кэширование результата
    this.cache.set(cacheKey, result);
    
    return result;
  }

  async executeOperation(data) {
    // Реализация основной логики операции
    // с учетом производительности
    return await this.connectionPool.execute(data);
  }

  generateCacheKey(data) {
    // Генерация ключа кэша на основе данных
    return JSON.stringify(data);
  }
}
```

### 2. Оптимизация ресурсов

Эффективное использование ресурсов системы:
- CPU
- Память
- Сеть
- Дисковое пространство
- Время выполнения

### 3. Архитектурные паттерны для производительности

#### Cache-Aside Pattern
```javascript
class CacheAsideService {
  constructor(cache, database) {
    this.cache = cache;
    this.database = database;
  }

  async getData(id) {
    // Попытка получения из кэша
    let data = await this.cache.get(id);
    
    if (!data) {
      // Если данных нет в кэше, получаем из базы
      data = await this.database.findById(id);
      
      // Сохраняем в кэш на будущее
      if (data) {
        await this.cache.set(id, data, { ttl: 300 }); // 5 минут
      }
    }
    
    return data;
  }

  async updateData(id, data) {
    // Обновляем в базе данных
    await this.database.update(id, data);
    
    // Удаляем из кэша, чтобы избежать несогласованности
    await this.cache.delete(id);
  }
}
```

#### Read-Through Pattern
```javascript
class ReadThroughCache {
  constructor(backend) {
    this.backend = backend;
    this.cache = new Map();
    this.cacheTimeout = 300000; // 5 минут
  }

  async get(key) {
    // Проверяем кэш
    if (this.cache.has(key)) {
      const { data, timestamp } = this.cache.get(key);
      
      // Проверяем, не истек ли срок кэширования
      if (Date.now() - timestamp < this.cacheTimeout) {
        return data;
      } else {
        // Удаляем устаревшие данные
        this.cache.delete(key);
      }
    }

    // Получаем данные из бэкенда
    const data = await this.backend.get(key);
    
    // Кэшируем данные
    this.cache.set(key, {
      data: data,
      timestamp: Date.now()
    });

    return data;
  }
}
```

#### Write-Through Pattern
```javascript
class WriteThroughCache {
  constructor(backend) {
    this.backend = backend;
    this.cache = new Map();
  }

  async set(key, value) {
    // Сначала записываем в бэкенд
    const result = await this.backend.set(key, value);
    
    // Если запись успешна, обновляем кэш
    if (result) {
      this.cache.set(key, value);
    }
    
    return result;
  }
}
```

## Performance Testing

### Типы Performance Testing

#### Load Testing
Тестирование приложения под ожидаемой рабочей нагрузкой:

```python
import time
import threading
import requests
from concurrent.futures import ThreadPoolExecutor
import statistics
from datetime import datetime

class LoadTester:
    def __init__(self, base_url, test_duration=60, concurrent_users=10):
        self.base_url = base_url
        self.test_duration = test_duration
        self.concurrent_users = concurrent_users
        self.results = []
        self.test_start_time = None
        self.test_end_time = None
    
    def single_request(self, url, method='GET', headers=None, data=None):
        """Выполнение одного запроса"""
        start_time = time.time()
        try:
            response = requests.request(method, url, headers=headers, data=data, timeout=30)
            end_time = time.time()
            
            result = {
                'timestamp': datetime.now(),
                'url': url,
                'method': method,
                'status_code': response.status_code,
                'response_time': (end_time - start_time) * 1000,  # в миллисекундах
                'response_size': len(response.content),
                'success': response.status_code < 400
            }
            return result
        except Exception as e:
            end_time = time.time()
            result = {
                'timestamp': datetime.now(),
                'url': url,
                'method': method,
                'status_code': None,
                'response_time': (end_time - start_time) * 1000,
                'response_size': 0,
                'success': False,
                'error': str(e)
            }
            return result
    
    def simulate_user_session(self, session_id):
        """Симуляция сессии пользователя"""
        session_results = []
        
        # Сценарий пользователя: последовательность запросов
        endpoints = [
            f"{self.base_url}/api/home",
            f"{self.base_url}/api/products",
            f"{self.base_url}/api/search?q=test",
            f"{self.base_url}/api/user/profile"
        ]
        
        for endpoint in endpoints:
            result = self.single_request(endpoint)
            session_results.append(result)
            
            # Имитация задержки между запросами (мышление пользователя)
            time.sleep(0.5)
        
        return session_results
    
    def run_load_test(self):
        """Запуск нагрузочного теста"""
        self.test_start_time = datetime.now()
        print(f"Начало нагрузочного теста: {self.test_start_time}")
        print(f"Конфигурация: {self.concurrent_users} пользователей, {self.test_duration} секунд")
        
        all_results = []
        
        # Запуск теста в течение заданного времени
        start_time = time.time()
        while time.time() - start_time < self.test_duration:
            # Создание пула потоков для симуляции пользователей
            with ThreadPoolExecutor(max_workers=self.concurrent_users) as executor:
                futures = [executor.submit(self.simulate_user_session, i) 
                          for i in range(self.concurrent_users)]
                
                for future in futures:
                    session_results = future.result()
                    all_results.extend(session_results)
            
            # Небольшая задержка между итерациями
            time.sleep(1)
        
        self.results = all_results
        self.test_end_time = datetime.now()
        
        print(f"Тест завершен: {self.test_end_time}")
        return all_results
    
    def generate_report(self):
        """Генерация отчета о тестировании"""
        if not self.results:
            return "Нет результатов для генерации отчета"
        
        successful_requests = [r for r in self.results if r['success']]
        failed_requests = [r for r in self.results if not r['success']]
        
        response_times = [r['response_time'] for r in successful_requests]
        
        report = {
            'test_duration': (self.test_end_time - self.test_start_time).total_seconds(),
            'total_requests': len(self.results),
            'successful_requests': len(successful_requests),
            'failed_requests': len(failed_requests),
            'success_rate': len(successful_requests) / len(self.results) * 100 if self.results else 0,
            'throughput': len(self.results) / (self.test_end_time - self.test_start_time).total_seconds(),
            'response_time_stats': {
                'min': min(response_times) if response_times else 0,
                'max': max(response_times) if response_times else 0,
                'avg': statistics.mean(response_times) if response_times else 0,
                'median': statistics.median(response_times) if response_times else 0,
                'p95': self._percentile(response_times, 95) if response_times else 0,
                'p99': self._percentile(response_times, 99) if response_times else 0
            },
            'error_details': [r['error'] for r in failed_requests if 'error' in r]
        }
        
        return report
    
    def _percentile(self, data, percentile):
        """Расчет перцентиля"""
        if not data:
            return 0
        sorted_data = sorted(data)
        index = (percentile / 100) * (len(sorted_data) - 1)
        if index.is_integer():
            return sorted_data[int(index)]
        else:
            lower = sorted_data[int(index)]
            upper = sorted_data[min(int(index) + 1, len(sorted_data) - 1)]
            fraction = index - int(index)
            return lower + fraction * (upper - lower)

# Пример использования нагрузочного тестера
# load_tester = LoadTester("http://localhost:8080", test_duration=30, concurrent_users=5)
# results = load_tester.run_load_test()
# report = load_tester.generate_report()
# print("Отчет о нагрузочном тесте:", report)
```

#### Stress Testing
Тестирование приложения под нагрузкой, превышающей нормальную:

```python
class StressTester:
    def __init__(self, base_url):
        self.base_url = base_url
        self.results = []
    
    def gradually_increase_load(self, start_users=1, max_users=100, step=5, duration_per_step=30):
        """Пошаговое увеличение нагрузки"""
        stress_results = []
        
        for users in range(start_users, max_users + 1, step):
            print(f"Тестирование с {users} пользователями...")
            
            # Использование ранее созданного LoadTester
            load_tester = LoadTester(self.base_url, test_duration=duration_per_step, concurrent_users=users)
            step_results = load_tester.run_load_test()
            step_report = load_tester.generate_report()
            
            stress_results.append({
                'users': users,
                'report': step_report
            })
            
            # Проверка на критические показатели
            if step_report['success_rate'] < 90:
                print(f"Критическое падение производительности при {users} пользователях")
                break
        
        return stress_results
    
    def peak_load_test(self, peak_users, duration=60):
        """Тестирование под пиковой нагрузкой"""
        print(f"Тестирование под пиковой нагрузкой: {peak_users} пользователей")
        
        load_tester = LoadTester(self.base_url, test_duration=duration, concurrent_users=peak_users)
        results = load_tester.run_load_test()
        report = load_tester.generate_report()
        
        return {
            'peak_users': peak_users,
            'report': report,
            'recovery_test': self.test_recovery(peak_users)
        }
    
    def test_recovery(self, peak_users):
        """Тестирование восстановления после стресса"""
        print("Тестирование восстановления...")
        
        # Снижение нагрузки до нормального уровня
        recovery_tester = LoadTester(self.base_url, test_duration=60, concurrent_users=10)
        results = recovery_tester.run_load_test()
        report = recovery_tester.generate_report()
        
        return report

# Пример стресс-тестирования
# stress_tester = StressTester("http://localhost:8080")
# stress_results = stress_tester.gradually_increase_load(start_users=1, max_users=50, step=5, duration_per_step=20)
# print(f"Результаты стресс-теста: {len(stress_results)} шагов")
```

#### Volume Testing
Тестирование с большими объемами данных:

```python
import os
import tempfile
import csv
import json

class VolumeTester:
    def __init__(self, base_url):
        self.base_url = base_url
    
    def generate_large_dataset(self, size_mb=100):
        """Генерация большого объема данных для тестирования"""
        # Создание временного файла с тестовыми данными
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.csv')
        
        rows_needed = int((size_mb * 1024 * 1024) / 100)  # приблизительно 100 байт на строку
        
        with open(temp_file.name, 'w', newline='') as csvfile:
            fieldnames = ['id', 'name', 'email', 'data']
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            
            for i in range(rows_needed):
                writer.writerow({
                    'id': i,
                    'name': f'User {i}',
                    'email': f'user{i}@example.com',
                    'data': 'x' * 50  # 50 символов данных
                })
        
        return temp_file.name
    
    def test_data_volume_operations(self, data_file_path):
        """Тестирование операций с большими объемами данных"""
        import requests
        
        # Загрузка большого файла
        with open(data_file_path, 'rb') as file:
            files = {'file': file}
            start_time = time.time()
            response = requests.post(f"{self.base_url}/api/upload", files=files)
            end_time = time.time()
        
        upload_result = {
            'operation': 'upload',
            'file_size_mb': os.path.getsize(data_file_path) / (1024 * 1024),
            'response_time': end_time - start_time,
            'status_code': response.status_code,
            'success': response.status_code < 400
        }
        
        # Тестирование поиска по большим данным
        search_start = time.time()
        search_response = requests.get(f"{self.base_url}/api/search?query=test&limit=10000")
        search_end = time.time()
        
        search_result = {
            'operation': 'search',
            'response_time': search_end - search_start,
            'status_code': search_response.status_code,
            'result_count': len(search_response.json()) if search_response.status_code == 200 else 0,
            'success': search_response.status_code < 400
        }
        
        return [upload_result, search_result]

# Пример тестирования объема данных
# volume_tester = VolumeTester("http://localhost:8080")
# data_file = volume_tester.generate_large_dataset(size_mb=50)  # 50MB
# volume_results = volume_tester.test_data_volume_operations(data_file)
# print("Результаты тестирования объема данных:", volume_results)
# os.unlink(data_file)  # Удаление временного файла
```

## Performance Monitoring

### Мониторинг производительности в CI/CD системах

Мониторинг производительности в системах непрерывной интеграции (CI/CD) является критически важным аспектом обеспечения стабильности, эффективности и надежности процессов доставки программного обеспечения. Он позволяет командам отслеживать производительность сборок, выявлять узкие места, оптимизировать ресурсы и обеспечивать высокое качество выпускаемых версий.

#### Основные метрики производительности CI/CD

##### Временные метрики
Сборка и доставка программного обеспечения требуют точного отслеживания времени выполнения различных этапов. Ключевые временные метрики включают:

- **Время выполнения сборки (Build Time)**: Общее время, затрачиваемое на выполнение всех задач сборки, от запуска до завершения
- **Время выполнения тестов (Test Execution Time)**: Время, затрачиваемое на выполнение всех тестов в pipeline
- **Время деплоя (Deployment Time)**: Время, необходимое для развертывания приложения в целевую среду
- **Время ожидания (Wait Time)**: Время, проведенное в ожидании ресурсов или выполнения зависимостей
- **Время отклика (Response Time)**: Время от отправки запроса на сборку до получения результата

Каждая из этих метрик помогает выявить узкие места в процессе CI/CD. Например, если время выполнения тестов значительно увеличивается, это может указывать на необходимость оптимизации тестов или выделения дополнительных ресурсов.

##### Метрики ресурсов
Эффективное использование ресурсов критически важно для оптимизации стоимости и производительности CI/CD:

- **Использование CPU**: Нагрузка на процессор во время выполнения задач
- **Использование памяти**: Объем оперативной памяти, используемой во время сборки
- **Использование дискового пространства**: Временное и постоянное использование хранилища
- **Сетевой трафик**: Объем данных, передаваемых во время сборки и деплоя
- **Использование контейнеров**: Количество и тип используемых контейнеров

##### Метрики качества
Качество процесса CI/CD также можно измерить с помощью следующих показателей:

- **Процент успешных сборок**: Отношение успешных сборок к общему числу
- **Среднее время до восстановления (MTTR)**: Время, необходимое для исправления неудачной сборки
- **Частота сбоев**: Количество сбоев в единицу времени
- **Покрытие тестами**: Процент кода, покрытый автоматизированными тестами
- **Количество уязвимостей**: Найденные безопасности в зависимости от критичности

#### Стратегии мониторинга производительности

##### Активный мониторинг
Активный мониторинг предполагает непрерывное отслеживание метрик во время выполнения процессов CI/CD. Это позволяет оперативно реагировать на проблемы и предотвращать сбои. Ключевые элементы активного мониторинга:

- **Реальное время**: Отслеживание метрик в режиме реального времени
- **Автоматические оповещения**: Уведомления о превышении пороговых значений
- **Профилирование производительности**: Подробный анализ использования ресурсов
- **Сравнение с базовыми показателями**: Сравнение текущих метрик с историческими данными

##### Пассивный мониторинг
Пассивный мониторинг фокусируется на сборе и анализе исторических данных для выявления тенденций и паттернов:

- **Хранение исторических данных**: Долгосрочное хранение метрик для анализа
- **Анализ трендов**: Выявление долгосрочных тенденций в производительности
- **Прогнозирование**: Использование исторических данных для прогнозирования будущей производительности
- **Отчеты**: Регулярные отчеты о производительности для заинтересованных сторон

##### Мониторинг по стадиям
Эффективный мониторинг производительности должен охватывать все стадии CI/CD:

- **Сборка**: Мониторинг времени компиляции, использования ресурсов, ошибок сборки
- **Тестирование**: Отслеживание времени выполнения тестов, покрытия, результатов
- **Деплой**: Мониторинг времени развертывания, статуса развертывания, ошибок
- **Пост-деплой**: Отслеживание состояния приложения после развертывания

#### Инструменты мониторинга

##### Встроенные инструменты CI/CD платформ
Большинство современных CI/CD платформ предоставляют встроенные возможности мониторинга:

- **Jenkins**: Plugin для мониторинга производительности, встроенные метрики
- **GitLab CI**: Встроенные метрики производительности, визуализация pipeline
- **GitHub Actions**: Метрики выполнения, время сборки, статистика использования
- **CircleCI**: Подробные метрики производительности, аналитика использования
- **Travis CI**: Временные метрики, статистика сборок

##### Специализированные инструменты мониторинга
Для более глубокого анализа производительности используются специализированные инструменты:

- **Prometheus**: Система мониторинга с мощным языком запросов
- **Grafana**: Платформа для визуализации и анализа метрик
- **Datadog**: Комплексное решение для мониторинга приложений и инфраструктуры
- **New Relic**: Платформа APM (Application Performance Monitoring)
- **Elastic Stack**: Лог-анализ и мониторинг с Kibana, Elasticsearch, Logstash

##### Инструменты профилирования
Для детального анализа производительности на уровне кода:

- **Jaeger**: Инструмент распределенного трейсинга
- **Zipkin**: Система трейсинга для анализа задержек в микросервисах
- **OpenTelemetry**: Открытая платформа для наблюдаемости
- **AppDynamics**: Платформа для мониторинга производительности приложений

#### Системы оповещения

##### Типы оповещений
Эффективная система оповещений должна включать следующие типы уведомлений:

- **Критические оповещения**: Немедленное уведомление о сбоях или серьезных проблемах
- **Предупреждения о производительности**: Уведомления о превышении пороговых значений
- **Оповещения об использовании ресурсов**: Уведомления о высокой нагрузке или нехватке ресурсов
- **Оповещения о качестве**: Уведомления о снижении покрытия тестами или увеличении уязвимостей

##### Пороговые значения
Установка правильных пороговых значений критически важна для эффективного мониторинга:

- **Динамические пороги**: Пороги, адаптирующиеся к историческим данным
- **Статические пороги**: Фиксированные значения, основанные на бизнес-требованиях
- **Процентные пороги**: Относительные пороги, основанные на процентах от максимальных значений
- **Сравнительные пороги**: Пороги, основанные на сравнении с предыдущими сборками

##### Каналы оповещения
Система оповещений должна использовать несколько каналов доставки:

- **Email**: Подробные отчеты и уведомления для несрочных проблем
- **Slack/Teams**: Быстрые уведомления для команды разработчиков
- **SMS/Telegram**: Критические оповещения для ответственных лиц
- **Внутренние системы**: Интеграция с системами управления задачами (Jira, Trello)

#### Панели мониторинга

##### Основные элементы панели мониторинга
Хорошая панель мониторинга CI/CD должна включать:

- **Обзор производительности**: Графики времени выполнения сборок
- **Статус pipeline**: Индикаторы текущего состояния всех pipeline
- **Метрики ресурсов**: Визуализация использования CPU, памяти, дискового пространства
- **Тренды**: Графики изменения метрик во времени
- **Качество кода**: Индикаторы покрытия тестами, количества уязвимостей

##### Примеры эффективных панелей
- **Панель разработчика**: Фокусируется на индивидуальной производительности и качестве кода
- **Панель команды**: Показывает производительность команды и проекта в целом
- **Панель руководства**: Агрегированные метрики, связанные с бизнес-показателями
- **Панель операций**: Фокусируется на стабильности и надежности процессов

##### Настройка панелей
При создании панелей мониторинга следует учитывать:

- **Целевая аудитория**: Разные роли требуют разных метрик
- **Частота обновления**: Баланс между актуальностью и нагрузкой на систему
- **Доступность**: Обеспечение доступа к панелям для всех заинтересованных сторон
- **Настройка**: Возможность кастомизации панелей под конкретные нужды

#### Интеграция с процессами сборки

##### Встраивание метрик в pipeline
Для эффективного мониторинга метрики должны быть интегрированы непосредственно в процесс сборки:

- **Сбор метрик на каждом этапе**: Регистрация времени и ресурсов для каждого шага
- **Сравнение с предыдущими сборками**: Автоматическое сравнение с базовыми показателями
- **Прерывание при превышении лимитов**: Автоматическая остановка сборки при превышении порогов
- **Логирование метрик**: Сохранение метрик для дальнейшего анализа

##### Автоматизация анализа
Современные системы CI/CD позволяют автоматизировать анализ производительности:

- **Анализ тенденций**: Автоматическое выявление ухудшения производительности
- **Рекомендации по оптимизации**: Предложения по улучшению производительности
- **Прогнозирование ресурсов**: Оценка необходимых ресурсов для будущих сборок
- **Сравнительный анализ**: Автоматическое сравнение с эталонными сборками

##### Интеграция с системами отслеживания задач
Связь мониторинга производительности с системами управления задачами:

- **Автоматическое создание задач**: Создание задач при обнаружении проблем
- **Связывание метрик с задачами**: Привязка данных производительности к конкретным задачам
- **Отслеживание прогресса**: Мониторинг улучшения после решения проблем
- **Отчеты для заинтересованных сторон**: Регулярные отчеты о производительности

## Тестирование производительности в CI

Тестирование производительности в непрерывной интеграции (CI) представляет собой критически важный аспект обеспечения качества современных приложений. В условиях, когда пользователи ожидают быстрого отклика и высокой доступности, регулярное тестирование производительности на ранних стадиях разработки становится обязательным требованием.

Интеграция тестирования производительности в CI позволяет:
- Рано выявлять узкие места в производительности
- Обнаруживать регрессии производительности при новых изменениях
- Обеспечивать стабильность производительности на протяжении всего жизненного цикла разработки
- Снижать риски производительности в продакшене

### Основные концепции Performance Testing в CI

#### Типы нагрузочного тестирования

##### Модульное тестирование производительности
- Тестирование отдельных компонентов на производительность
- Измерение времени выполнения конкретных операций
- Проверка использования ресурсов (память, CPU)

##### Интеграционное тестирование производительности
- Тестирование взаимодействия между компонентами
- Проверка производительности API-вызовов
- Оценка производительности баз данных

##### End-to-end тестирование производительности
- Тестирование полного пользовательского сценария
- Симуляция реальных пользовательских сценариев
- Проверка производительности в реальных условиях

#### Метрики производительности

##### Временные метрики
- Время отклика (Response Time)
- Время загрузки страницы (Page Load Time)
- Время выполнения запроса (Request Time)
- Время выполнения транзакции (Transaction Time)

##### Пропускная способность
- Количество запросов в секунду (Requests Per Second - RPS)
- Пропускная способность (Throughput)
- Скорость передачи данных (Data Transfer Rate)

##### Ресурсные метрики
- Использование CPU
- Использование памяти (Memory Usage)
- Использование дискового пространства
- Использование сетевых ресурсов

### Инструменты для Performance Testing в CI

#### Apache JMeter
JMeter - один из самых популярных инструментов для нагрузочного тестирования:

```xml
<!-- Пример JMX-файла для JMeter -->
<?xml version="1.0" encoding="UTF-8"?>
<jmeterTestPlan version="1.2" properties="5.0" jmeter="5.4.1">
  <hashTree>
    <TestPlan guiclass="TestPlanGui" testclass="TestPlan" testname="Performance Test Plan">
      <elementProp name="TestPlan.arguments" elementType="Arguments" guiclass="ArgumentsPanel" testclass="Arguments">
        <collectionProp name="Arguments.arguments"/>
      </elementProp>
      <stringProp name="TestPlan.user_define_classpath"></stringProp>
    </TestPlan>
    <hashTree>
      <ThreadGroup guiclass="ThreadGroupGui" testclass="ThreadGroup" testname="User Load Simulation">
        <stringProp name="ThreadGroup.num_threads">100</stringProp>
        <stringProp name="ThreadGroup.ramp_time">60</stringProp>
        <stringProp name="ThreadGroup.duration">300</stringProp>
      </ThreadGroup>
      <hashTree>
        <HTTPSamplerProxy guiclass="HttpTestSampleGui" testclass="HTTPSamplerProxy" testname="API Endpoint Test">
          <stringProp name="HTTPSampler.domain">api.example.com</stringProp>
          <stringProp name="HTTPSampler.port">443</stringProp>
          <stringProp name="HTTPSampler.path">/users</stringProp>
          <stringProp name="HTTPSampler.method">GET</stringProp>
        </HTTPSamplerProxy>
        <hashTree/>
      </hashTree>
    </hashTree>
  </hashTree>
</jmeterTestPlan>
```

#### Запуск JMeter в CI
```bash
# Пример команды для запуска JMeter в режиме CLI
jmeter -n -t performance-test.jmx -l results.jtl -e -o /path/to/report

# Генерация HTML-отчета
jmeter -g results.jtl -o /path/to/html-report
```

#### Gatling
Gatling - современный инструмент для нагрузочного тестирования с открытым исходным кодом:

```scala
// Пример сценария Gatling
import io.gatling.core.Predef._
import io.gatling.http.Predef._

class PerformanceSimulation extends Simulation {
  
  val httpProtocol = http
    .baseUrl("https://api.example.com")
    .acceptHeader("application/json")
  
  val scn = scenario("API Load Test")
    .exec(
      http("Get Users")
        .get("/users")
        .check(status.is(200))
        .check(jsonPath("$.length()").gte(10))
    )
    .pause(1)
    .exec(
      http("Get Specific User")
        .get("/users/${userId}")
        .check(status.is(200))
    )
  
  setUp(
    scn.inject(
      rampUsers(100) during (60 seconds),
      constantUsersPerSec(50) during (300 seconds)
    ).protocols(httpProtocol)
  )
}
```

#### Интеграция Gatling с Maven
```xml
<plugin>
  <groupId>io.gatling</groupId>
  <artifactId>gatling-maven-plugin</artifactId>
  <version>3.0.5</version>
  <configuration>
    <simulationClass>com.example.PerformanceSimulation</simulationClass>
  </configuration>
</plugin>
```

#### k6
k6 - современный инструмент для тестирования производительности с поддержкой JavaScript:

```javascript
// Пример скрипта k6
import http from 'k6/http';
import { check, sleep } from 'k6';

export const options = {
  stages: [
    { duration: '1m', target: 10 },
    { duration: '3m', target: 10 },
    { duration: '1m', target: 0 },
  ],
  thresholds: {
    http_req_duration: ['p(95)<1000'], // 95% запросов должны выполняться менее чем за 1 секунду
    http_req_failed: ['rate<0.01'],    // Менее 1% неудачных запросов
  },
};

export default function () {
  const res = http.get('https://api.example.com/users');
  check(res, {
    'status is 200': (r) => r.status === 200,
    'response time < 500ms': (r) => r.timings.duration < 500,
  });
  sleep(1);
}
```

### Стратегии интеграции Performance Testing в CI

#### 1. Smoke Performance Tests
Легкие тесты производительности, запускаемые при каждом билде:

```yaml
# Пример GitHub Actions для Smoke Performance Tests
name: Smoke Performance Tests
on:
  push:
    branches: [ develop, feature/** ]
  pull_request:
    branches: [ main ]

jobs:
  performance-test:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
    
    - name: Setup k6
      run: |
        sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
        echo "deb https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
        sudo apt-get update
        sudo apt-get install k6
    
    - name: Run smoke performance tests
      run: |
        k6 run --duration 30s --vus 5 smoke-test.js
```

#### 2. Regression Performance Tests
Тесты для выявления регрессий производительности:

```groovy
// Пример Jenkinsfile для Regression Performance Tests
pipeline {
    agent any
    
    stages {
        stage('Build') {
            steps {
                sh 'npm install'
                sh 'npm run build'
            }
        }
        
        stage('Deploy to Test Environment') {
            steps {
                sh 'kubectl apply -f deployment-test.yaml'
            }
        }
        
        stage('Wait for Deployment') {
            steps {
                sh 'kubectl rollout status deployment/test-app --timeout=300s'
            }
        }
        
        stage('Performance Regression Test') {
            steps {
                sh '''
                k6 run \
                  --out json=results.json \
                  --summary-export=summary.json \
                  regression-test.js
                '''
            }
        }
        
        stage('Compare Results') {
            steps {
                sh '''
                node compare-results.js \
                  --baseline baseline-results.json \
                  --current results.json \
                  --threshold 5
                '''
            }
        }
    }
}
```

#### 3. Load Testing в Staging Environment
Более интенсивные нагрузочные тесты в staging-окружении:

```yaml
# Пример конфигурации для нагрузочного тестирования
name: Load Testing
on:
  schedule:
    - cron: '0 2 * * 1'  # Еженедельно в понедельник в 2:00 UTC
  workflow_dispatch:  # Возможность запуска вручную

jobs:
  load-test:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
    
    - name: Setup k6
      run: |
        sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
        echo "deb https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
        sudo apt-get update
        sudo apt-get install k6
    
    - name: Run load test
      run: |
        k6 run \
          --out cloud \
          --duration 10m \
          --vus 100 \
          load-test.js
      env:
        K6_CLOUD_TOKEN: ${{ secrets.K6_CLOUD_TOKEN }}
```

### Метрики и пороговые значения

#### 1. Определение SLA (Service Level Agreement)
Для эффективного тестирования производительности в CI необходимо определить SLA:

```javascript
// Пример определения SLA в k6
export const options = {
  thresholds: {
    // Временные метрики
    'http_req_duration{api:users}': ['p(95)<800', 'p(99)<1200'],
    'http_req_duration{api:orders}': ['p(95)<500', 'p(99)<800'],
    
    // Метрики ошибок
    'http_req_failed': ['rate<0.01'],  // Менее 1% ошибок
    
    // Метрики пропускной способности
    'http_reqs{api:users}': ['count>1000'],  // Более 1000 запросов за тест
    
    // Пользовательские метрики
    'page_load_time': ['p(95)<2000'],
  },
};
```

#### 2. Мониторинг ресурсов
Сбор метрик использования ресурсов во время тестирования:

```javascript
// Пример пользовательской метрики в k6
import { Counter, Rate, Trend } from 'k6/metrics';

const requestDuration = new Trend('request_duration');
const errorCount = new Counter('errors');
const errorRate = new Rate('error_rate');

export default function () {
  const start = Date.now();
  const res = http.get('https://api.example.com/users');
  const end = Date.now();
  
  requestDuration.add(end - start);
  
  if (res.status >= 400) {
    errorCount.add(1);
    errorRate.add(1);
  } else {
    errorRate.add(0);
  }
}
```

### Реализация Performance Testing Pipeline

#### 1. Подготовка тестовой среды
Для эффективного тестирования производительности в CI необходимо настроить соответствующую тестовую среду:

```yaml
# Пример Docker Compose для тестовой среды
version: '3.8'
services:
  app:
    build: .
    environment:
      - DB_HOST=database
      - REDIS_HOST=cache
    depends_on:
      - database
      - cache
    ports:
      - "8080:8080"
  
  database:
    image: postgres:13
    environment:
      POSTGRES_DB: testdb
      POSTGRES_USER: testuser
      POSTGRES_PASSWORD: testpass
    volumes:
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
  
  cache:
    image: redis:6-alpine
    ports:
      - "6379:6379"
  
  load-tester:
    image: grafana/k6:latest
    volumes:
      - ./performance-tests:/scripts
    command: run /scripts/test.js
    depends_on:
      - app
```

#### 2. Сравнение результатов
Сравнение результатов тестов для выявления регрессий:

```javascript
// Пример скрипта для сравнения результатов
const fs = require('fs');

function compareResults(baseline, current, threshold) {
  const baselineData = JSON.parse(fs.readFileSync(baseline, 'utf8'));
  const currentData = JSON.parse(fs.readFileSync(current, 'utf8'));
  
  const baselineAvg = baselineData.metrics.http_req_duration.avg;
  const currentAvg = currentData.metrics.http_req_duration.avg;
  
  const diff = ((currentAvg - baselineAvg) / baselineAvg) * 100;
  
  if (diff > threshold) {
    console.error(`Performance regression detected: ${diff.toFixed(2)}% degradation`);
    process.exit(1);
  } else {
    console.log(`Performance OK: ${diff.toFixed(2)}% difference`);
  }
}

// Использование: node compare-results.js --baseline baseline.json --current current.json --threshold 5
const args = process.argv.slice(2);
const baseline = args.find(arg => arg.startsWith('--baseline=')).split('=')[1];
const current = args.find(arg => arg.startsWith('--current=')).split('=')[1];
const threshold = parseFloat(args.find(arg => arg.startsWith('--threshold=')).split('=')[1]);

compareResults(baseline, current, threshold);
```

#### 3. Интеграция с системами мониторинга
Интеграция результатов тестирования с системами мониторинга:

```javascript
// Пример интеграции с Prometheus
import { Counter, Gauge } from 'k6/metrics';
import http from 'k6/http';

const requestsTotal = new Counter('http_requests_total');
const responseTimeGauge = new Gauge('http_response_time_seconds');

export default function () {
  const start = Date.now();
  const res = http.get('https://api.example.com/users');
  const end = Date.now();
  
  requestsTotal.add(1);
  responseTimeGauge.add((end - start) / 1000);
  
  // Отправка метрик в Prometheus Pushgateway
  http.post('http://pushgateway:9091/metrics/job/performance_test', 
    generatePrometheusMetrics((end - start) / 1000, res.status)
  );
}

function generatePrometheusMetrics(responseTime, statusCode) {
  return `# TYPE http_response_time_seconds gauge
http_response_time_seconds ${responseTime}
# TYPE http_requests_total counter
http_requests_total{status="${statusCode}"} 1
`;
}
```

### Лучшие практики

#### 1. Оптимизация тестов для CI
- Использование легких тестов для проверки основных функций
- Сокращение времени выполнения тестов
- Использование параллельного выполнения
- Кеширование результатов для ускорения

#### 2. Управление ресурсами
- Изолирование тестов производительности от других тестов
- Использование dedicated-окружений для тестирования
- Мониторинг использования ресурсов CI-агента
- Ограничение нагрузки для предотвращения перегрузки

#### 3. Обработка результатов
- Автоматическое сравнение с базовыми значениями
- Генерация отчетов о производительности
- Интеграция с системами уведомлений
- Архивирование результатов для анализа

## Performance Optimization Techniques

### Frontend Performance Optimization

#### 1. Asset Optimization
```javascript
// Пример оптимизации ассетов в webpack
module.exports = {
  optimization: {
    splitChunks: {
      chunks: 'all',
      cacheGroups: {
        vendor: {
          test: /[\\/]node_modules[\\/]/,
          name: 'vendors',
          chunks: 'all',
        },
        common: {
          name: 'common',
          minChunks: 2,
          chunks: 'all',
          enforce: true
        }
      }
    },
    minimizer: [
      new TerserPlugin({
        terserOptions: {
          compress: {
            drop_console: true, // Удаление console.log в продакшене
          },
        },
      }),
    ],
  },
  module: {
    rules: [
      {
        test: /\.(png|jpe?g|gif|svg)$/i,
        use: [
          {
            loader: 'image-webpack-loader',
            options: {
              mozjpeg: {
                progressive: true,
                quality: 65
              },
              optipng: {
                enabled: false,
              },
              pngquant: {
                quality: [0.65, 0.90],
                speed: 4
              },
              gifsicle: {
                interlaced: false,
              }
            }
          }
        ]
      }
    ]
  }
};
```

#### 2. Code Splitting and Lazy Loading
```javascript
// Пример ленивой загрузки компонентов в React
import { lazy, Suspense } from 'react';

const Dashboard = lazy(() => import('./Dashboard'));
const Reports = lazy(() => import('./Reports'));
const Settings = lazy(() => import('./Settings'));

function App() {
  return (
    <div>
      <nav>
        <Link to="/dashboard">Dashboard</Link>
        <Link to="/reports">Reports</Link>
        <Link to="/settings">Settings</Link>
      </nav>
      
      <Suspense fallback={<div>Loading...</div>}>
        <Routes>
          <Route path="/dashboard" element={<Dashboard />} />
          <Route path="/reports" element={<Reports />} />
          <Route path="/settings" element={<Settings />} />
        </Routes>
      </Suspense>
    </div>
  );
}

// Пример динамического импорта
async function loadFeature() {
  const { heavyFeature } = await import('./heavy-feature');
  return heavyFeature;
}
```

#### 3. Caching Strategies
```javascript
// Пример стратегии кэширования в Service Worker
const CACHE_NAME = 'app-v1.2.3';
const urlsToCache = [
  '/',
  '/styles/main.css',
  '/scripts/main.js',
  '/images/logo.png'
];

self.addEventListener('install', event => {
  event.waitUntil(
    caches.open(CACHE_NAME)
      .then(cache => cache.addAll(urlsToCache))
  );
});

self.addEventListener('fetch', event => {
  event.respondWith(
    caches.match(event.request)
      .then(response => {
        // Возврат кэшированного ответа или сетевого запроса
        return response || fetch(event.request);
      }
    )
  );
});
```

### Backend Performance Optimization

#### 1. Database Optimization
```javascript
// Пример оптимизации запросов к базе данных
class OptimizedUserService {
  constructor(db) {
    this.db = db;
  }

  // Использование индексов
  async findUsersByStatus(status, page = 1, limit = 10) {
    // Использование индекса по полю status
    const offset = (page - 1) * limit;
    
    const [users, total] = await Promise.all([
      this.db.query(`
        SELECT id, name, email, status, created_at
        FROM users 
        WHERE status = ?
        ORDER BY created_at DESC
        LIMIT ? OFFSET ?
      `, [status, limit, offset]),
      
      this.db.query(`
        SELECT COUNT(*) as count
        FROM users 
        WHERE status = ?
      `, [status])
    ]);

    return {
      users,
      total: total[0].count,
      page,
      limit
    };
  }

  // Использование соединений
  async getUsersWithOrders(userId) {
    // Оптимизированный запрос с JOIN
    return await this.db.query(`
      SELECT u.id, u.name, u.email, o.id as order_id, o.total, o.status
      FROM users u
      LEFT JOIN orders o ON u.id = o.user_id
      WHERE u.id = ?
      ORDER BY o.created_at DESC
    `, [userId]);
  }
}
```

#### 2. API Optimization
```javascript
// Пример оптимизации API с пагинацией и фильтрацией
class OptimizedAPI {
  constructor() {
    this.cache = new Map();
    this.cacheTimeout = 300000; // 5 минут
  }

  async getUsers(req, res) {
    const {
      page = 1,
      limit = 10,
      sort = 'created_at',
      order = 'desc',
      status,
      search
    } = req.query;

    // Генерация ключа кэша
    const cacheKey = `users:${page}:${limit}:${sort}:${order}:${status}:${search}`;
    const cached = this.cache.get(cacheKey);

    if (cached && Date.now() - cached.timestamp < this.cacheTimeout) {
      return res.json(cached.data);
    }

    // Построение оптимизированного запроса
    let query = 'SELECT * FROM users WHERE 1=1';
    const params = [];

    if (status) {
      query += ' AND status = ?';
      params.push(status);
    }

    if (search) {
      query += ' AND (name LIKE ? OR email LIKE ?)';
      params.push(`%${search}%`, `%${search}%`);
    }

    query += ` ORDER BY ${sort} ${order} LIMIT ? OFFSET ?`;
    params.push(parseInt(limit), (parseInt(page) - 1) * parseInt(limit));

    const users = await this.db.query(query, params);

    // Кэширование результата
    const result = { users, pagination: { page, limit } };
    this.cache.set(cacheKey, {
      data: result,
      timestamp: Date.now()
    });

    res.json(result);
  }
}
```

#### 3. Memory Management
```javascript
// Пример управления памятью
class MemoryEfficientProcessor {
  constructor() {
    this.buffer = [];
    this.bufferSize = 1000;
    this.processInterval = 5000; // 5 секунд
    this.startProcessing();
  }

  addItem(item) {
    this.buffer.push(item);
    
    // Очистка буфера при достижении лимита
    if (this.buffer.length >= this.bufferSize) {
      this.processBuffer();
    }
  }

  processBuffer() {
    // Обработка буфера
    const items = this.buffer.splice(0, this.bufferSize);
    
    // Асинхронная обработка
    setImmediate(() => {
      this.handleItems(items);
    });
  }

  startProcessing() {
    // Регулярная очистка буфера
    setInterval(() => {
      if (this.buffer.length > 0) {
        this.processBuffer();
      }
    }, this.processInterval);
  }

  handleItems(items) {
    // Логика обработки элементов
    for (const item of items) {
      // Обработка элемента
      this.processItem(item);
    }
  }

  processItem(item) {
    // Реализация обработки элемента
    console.log('Processing item:', item);
  }
}
```

## Performance Architecture Patterns

### 1. Circuit Breaker Pattern for Performance
```javascript
// Реализация Circuit Breaker для защиты от перегрузки
class PerformanceCircuitBreaker {
  constructor(options = {}) {
    this.failureThreshold = options.failureThreshold || 5;
    this.timeout = options.timeout || 60000;
    this.resetTimeout = options.resetTimeout || 30000;
    this.state = 'CLOSED';
    this.failureCount = 0;
    this.lastFailureTime = null;
    this.nextAttemptTime = null;
    this.metrics = {
      successCount: 0,
      failureCount: 0,
      totalRequests: 0,
      averageResponseTime: 0
    };
  }

  async call(operation) {
    if (this.state === 'OPEN') {
      if (Date.now() >= this.nextAttemptTime) {
        this.state = 'HALF_OPEN';
      } else {
        throw new Error('Circuit breaker is OPEN');
      }
    }

    this.metrics.totalRequests++;
    const startTime = Date.now();

    try {
      const result = await operation();
      const responseTime = Date.now() - startTime;
      
      this.onSuccess(responseTime);
      return result;
    } catch (error) {
      const responseTime = Date.now() - startTime;
      this.onFailure(responseTime);
      throw error;
    }
  }

  onSuccess(responseTime) {
    this.failureCount = 0;
    this.state = 'CLOSED';
    this.lastFailureTime = null;
    this.nextAttemptTime = null;
    
    // Обновление метрик
    this.metrics.successCount++;
    this.metrics.averageResponseTime = 
      (this.metrics.averageResponseTime * (this.metrics.successCount - 1) + responseTime) / this.metrics.successCount;
  }

  onFailure(responseTime) {
    this.failureCount++;
    this.lastFailureTime = Date.now();
    
    if (this.failureCount >= this.failureThreshold) {
      this.state = 'OPEN';
      this.nextAttemptTime = Date.now() + this.resetTimeout;
      this.metrics.failureCount++;
    }
  }

  getMetrics() {
    return { ...this.metrics, state: this.state, failureCount: this.failureCount };
  }
}
```

### 2. Bulkhead Pattern
```javascript
// Реализация Bulkhead Pattern для изоляции ресурсов
class BulkheadPattern {
  constructor() {
    this.servicePools = {
      critical: new WorkerPool(5),  // Критические операции
      standard: new WorkerPool(10), // Стандартные операции
      background: new WorkerPool(3) // Фоновые операции
    };
  }

  async executeCriticalTask(task) {
    return await this.servicePools.critical.execute(task);
  }

  async executeStandardTask(task) {
    return await this.servicePools.standard.execute(task);
  }

  async executeBackgroundTask(task) {
    return await this.servicePools.background.execute(task);
  }
}

class WorkerPool {
  constructor(maxWorkers) {
    this.maxWorkers = maxWorkers;
    this.activeWorkers = 0;
    this.taskQueue = [];
  }

  async execute(task) {
    if (this.activeWorkers < this.maxWorkers) {
      this.activeWorkers++;
      try {
        const result = await task();
        this.activeWorkers--;
        this.processNext();
        return result;
      } catch (error) {
        this.activeWorkers--;
        this.processNext();
        throw error;
      }
    } else {
      // Добавление задачи в очередь
      return new Promise((resolve, reject) => {
        this.taskQueue.push({ task, resolve, reject });
      });
    }
  }

  processNext() {
    if (this.taskQueue.length > 0 && this.activeWorkers < this.maxWorkers) {
      const { task, resolve, reject } = this.taskQueue.shift();
      this.execute(task())
        .then(resolve)
        .catch(reject);
    }
  }
}
```

### 3. Throttling and Rate Limiting
```javascript
// Реализация Rate Limiting
class RateLimiter {
  constructor(options = {}) {
    this.maxRequests = options.maxRequests || 100;
    this.windowMs = options.windowMs || 60000; // 1 minute
    this.clients = new Map();
  }

  isAllowed(clientId) {
    const now = Date.now();
    let client = this.clients.get(clientId);

    if (!client) {
      client = { count: 0, resetTime: now + this.windowMs };
      this.clients.set(clientId, client);
    }

    if (now > client.resetTime) {
      // Сброс лимита
      client.count = 0;
      client.resetTime = now + this.windowMs;
    }

    if (client.count >= this.maxRequests) {
      return false; // Лимит превышен
    }

    client.count++;
    return true;
  }

  cleanup() {
    const now = Date.now();
    for (const [clientId, client] of this.clients.entries()) {
      if (now > client.resetTime) {
        this.clients.delete(clientId);
      }
    }
  }
}

// Использование в Express.js
const rateLimiter = new RateLimiter({ maxRequests: 100, windowMs: 60000 });

app.use((req, res, next) => {
  if (!rateLimiter.isAllowed(req.ip)) {
    return res.status(429).json({ error: 'Rate limit exceeded' });
  }
  next();
});
```

## Performance Monitoring and Observability

### 1. Distributed Tracing
```javascript
// Пример распределенного трейсинга
class DistributedTracer {
  constructor() {
    this.traces = new Map();
  }

  startTrace(operationName, parentTraceId = null) {
    const traceId = this.generateId();
    const spanId = this.generateId();
    
    const trace = {
      traceId,
      spans: [{
        spanId,
        operationName,
        startTime: Date.now(),
        parentSpanId: parentTraceId,
        tags: {},
        logs: []
      }]
    };
    
    this.traces.set(traceId, trace);
    return { traceId, spanId };
  }

  addTag(traceId, spanId, key, value) {
    const trace = this.traces.get(traceId);
    if (trace) {
      const span = trace.spans.find(s => s.spanId === spanId);
      if (span) {
        span.tags[key] = value;
      }
    }
  }

  addLog(traceId, spanId, message, timestamp = Date.now()) {
    const trace = this.traces.get(traceId);
    if (trace) {
      const span = trace.spans.find(s => s.spanId === spanId);
      if (span) {
        span.logs.push({ message, timestamp });
      }
    }
  }

  endTrace(traceId, spanId) {
    const trace = this.traces.get(traceId);
    if (trace) {
      const span = trace.spans.find(s => s.spanId === spanId);
      if (span) {
        span.endTime = Date.now();
        span.duration = span.endTime - span.startTime;
      }
    }
  }

  generateId() {
    return Math.random().toString(36).substr(2, 9);
  }
}
```

### 2. Metrics Collection
```javascript
// Система сбора метрик
class MetricsCollector {
  constructor() {
    this.counters = new Map();
    this.gauges = new Map();
    this.histograms = new Map();
    this.timers = new Map();
  }

  increment(name, value = 1) {
    const current = this.counters.get(name) || 0;
    this.counters.set(name, current + value);
  }

  setGauge(name, value) {
    this.gauges.set(name, value);
  }

  recordHistogram(name, value) {
    if (!this.histograms.has(name)) {
      this.histograms.set(name, []);
    }
    this.histograms.get(name).push(value);
  }

  startTimer(name) {
    const startTime = process.hrtime();
    this.timers.set(name, startTime);
  }

  stopTimer(name) {
    const startTime = this.timers.get(name);
    if (startTime) {
      const [seconds, nanoseconds] = process.hrtime(startTime);
      const duration = seconds * 1000 + nanoseconds / 1e6;
      this.recordHistogram(`${name}_duration`, duration);
      this.timers.delete(name);
      return duration;
    }
  }

  getMetrics() {
    const metrics = {
      counters: Object.fromEntries(this.counters),
      gauges: Object.fromEntries(this.gauges),
      histograms: {}
    };

    for (const [name, values] of this.histograms) {
      if (values.length > 0) {
        const sorted = [...values].sort((a, b) => a - b);
        metrics.histograms[name] = {
          count: values.length,
          sum: values.reduce((a, b) => a + b, 0),
          min: sorted[0],
          max: sorted[sorted.length - 1],
          avg: values.reduce((a, b) => a + b, 0) / values.length,
          p50: sorted[Math.floor(sorted.length * 0.5)],
          p95: sorted[Math.floor(sorted.length * 0.95)],
          p99: sorted[Math.floor(sorted.length * 0.99)]
        };
      }
    }

    return metrics;
  }
}
```

## Performance Testing Best Practices

### 1. Continuous Performance Testing
```javascript
import unittest
from datetime import datetime, timedelta

class PerformanceTestCase(unittest.TestCase):
    """Класс для тестов производительности, совместимый с unittest"""
    
    def setUp(self):
        self.load_tester = LoadTester("http://localhost:8080", test_duration=10, concurrent_users=5)
    
    def test_response_time_under_load(self):
        """Тест: время отклика не должно превышать 500мс при нагрузке"""
        results = self.load_tester.run_load_test()
        report = self.load_tester.generate_report()
        
        # Проверка 95-го перцентиля времени отклика
        p95_response_time = report['response_time_stats']['p95']
        self.assertLess(p95_response_time, 500, 
                       f"P95 время отклика {p95_response_time}мс превышает лимит 500мс")
    
    def test_success_rate(self):
        """Тест: успешность запросов должна быть не менее 95%"""
        results = self.load_tester.run_load_test()
        report = self.load_tester.generate_report()
        
        success_rate = report['success_rate']
        self.assertGreaterEqual(success_rate, 95.0,
                               f"Процент успешных запросов {success_rate}% ниже требуемых 95%")
    
    def test_throughput_requirements(self):
        """Тест: пропускная способность должна быть не менее 10 RPS"""
        results = self.load_tester.run_load_test()
        report = self.load_tester.generate_report()
        
        throughput = report['throughput']
        self.assertGreaterEqual(throughput, 10.0,
                               f"Пропускная способность {throughput} RPS ниже требуемых 10 RPS")
```

### 2. Performance Regression Testing
```javascript
import json
import os
from datetime import datetime

class PerformanceRegressionTester:
    def __init__(self, baseline_file="performance_baseline.json"):
        self.baseline_file = baseline_file
        self.current_results = {}
    
    def establish_baseline(self, test_results):
        """Установление базовой линии производительности"""
        baseline = {
            'timestamp': datetime.now().isoformat(),
            'test_results': test_results,
            'metrics': self._extract_key_metrics(test_results)
        }
        
        with open(self.baseline_file, 'w') as f:
            json.dump(baseline, f, indent=2)
        
        print(f"Базовая линия сохранена в {self.baseline_file}")
        return baseline
    
    def load_baseline(self):
        """Загрузка базовой линии"""
        if os.path.exists(self.baseline_file):
            with open(self.baseline_file, 'r') as f:
                return json.load(f)
        return None
    
    def compare_with_baseline(self, current_results, threshold_percent=10):
        """Сравнение текущих результатов с базовой линией"""
        baseline = self.load_baseline()
        if not baseline:
            print("Базовая линия не найдена. Установите базовую линию сначала.")
            return None
        
        current_metrics = self._extract_key_metrics(current_results)
        baseline_metrics = baseline['metrics']
        
        regression_issues = []
        
        # Сравнение ключевых метрик
        metrics_to_check = [
            'response_time_stats.avg',
            'response_time_stats.p95',
            'success_rate',
            'throughput'
        ]
        
        for metric_path in metrics_to_check:
            current_value = self._get_nested_value(current_metrics, metric_path)
            baseline_value = self._get_nested_value(baseline_metrics, metric_path)
            
            if current_value and baseline_value:
                if metric_path in ['response_time_stats.avg', 'response_time_stats.p95']:
                    # Для времени отклика регрессия = ухудшение (увеличение)
                    if current_value > baseline_value * (1 + threshold_percent / 100):
                        regression_issues.append({
                            'metric': metric_path,
                            'baseline': baseline_value,
                            'current': current_value,
                            'change': f"+{((current_value - baseline_value) / baseline_value * 100):.2f}%",
                            'regression': True
                        })
                elif metric_path in ['success_rate', 'throughput']:
                    # Для успеха/пропускной способности регрессия = ухудшение (уменьшение)
                    if current_value < baseline_value * (1 - threshold_percent / 100):
                        regression_issues.append({
                            'metric': metric_path,
                            'baseline': baseline_value,
                            'current': current_value,
                            'change': f"{((current_value - baseline_value) / baseline_value * 100):.2f}%",
                            'regression': True
                        })
        
        return {
            'regression_issues': regression_issues,
            'performance_ok': len(regression_issues) == 0,
            'baseline_timestamp': baseline['timestamp']
        }
    
    def _extract_key_metrics(self, results):
        """Извлечение ключевых метрик из результатов"""
        # Предполагается, что results - это отчет из LoadTester
        if isinstance(results, dict):
            return results
        return {}
    
    def _get_nested_value(self, obj, path):
        """Получение вложенного значения по пути (например, 'response_time_stats.avg')"""
        keys = path.split('.')
        value = obj
        for key in keys:
            if isinstance(value, dict) and key in value:
                value = value[key]
            else:
                return None
        return value
```

## Modern Performance Approaches

### 1. AI-Driven Performance Optimization
```javascript
import numpy as np
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler

class AIPerformanceAnalyzer:
    def __init__(self):
        self.anomaly_detector = IsolationForest(contamination=0.1, random_state=42)
        self.scaler = StandardScaler()
        self.metrics_history = []
    
    def collect_performance_metrics(self, response_times, error_rates, throughput):
        """Сбор метрик производительности"""
        metrics = {
            'avg_response_time': np.mean(response_times) if response_times else 0,
            'p95_response_time': np.percentile(response_times, 95) if response_times else 0,
            'error_rate': np.mean(error_rates) if error_rates else 0,
            'throughput': np.mean(throughput) if throughput else 0,
            'timestamp': datetime.now().timestamp()
        }
        
        self.metrics_history.append(metrics)
        return metrics
    
    def detect_anomalies(self):
        """Обнаружение аномалий в метриках производительности"""
        if len(self.metrics_history) < 10:  # Нужно минимум 10 точек данных
            return []
        
        # Подготовка данных для ML
        features = []
        for metrics in self.metrics_history:
            features.append([
                metrics['avg_response_time'],
                metrics['p95_response_time'],
                metrics['error_rate'],
                metrics['throughput']
            ])
        
        # Нормализация данных
        scaled_features = self.scaler.fit_transform(features)
        
        # Обнаружение аномалий
        anomaly_labels = self.anomaly_detector.fit_predict(scaled_features)
        
        anomalies = []
        for i, label in enumerate(anomaly_labels):
            if label == -1:  # -1 означает аномалию
                anomalies.append({
                    'index': i,
                    'timestamp': self.metrics_history[i]['timestamp'],
                    'metrics': self.metrics_history[i],
                    'anomaly_type': self._classify_anomaly(self.metrics_history[i])
                })
        
        return anomalies
    
    def _classify_anomaly(self, metrics):
        """Классификация типа аномалии"""
        if metrics['avg_response_time'] > 2 * np.mean([m['avg_response_time'] for m in self.metrics_history[:-1]] or [1]):
            return 'slow_response'
        elif metrics['error_rate'] > 0.05:  # > 5% ошибок
            return 'high_error_rate'
        elif metrics['throughput'] < 0.5 * np.mean([m['throughput'] for m in self.metrics_history[:-1]] or [1]):
            return 'low_throughput'
        else:
            return 'other'
    
    def predict_performance_degradation(self):
        """Предсказание возможного ухудшения производительности"""
        # В реальности использовались бы более сложные модели (LSTM, ARIMA и т.д.)
        if len(self.metrics_history) < 5:
            return {'risk_level': 'low', 'confidence': 0.0}
        
        # Простой анализ тренда для среднего времени отклика
        response_times = [m['avg_response_time'] for m in self.metrics_history]
        if len(response_times) >= 5:
            recent_trend = response_times[-5:]  # последние 5 измерений
            if len(set(recent_trend)) > 1:  # есть изменения
                # Простой линейный тренд
                x = list(range(len(recent_trend)))
                slope = np.polyfit(x, recent_trend, 1)[0]
                
                if slope > 0:  # тренд роста
                    risk_level = 'high' if slope > np.mean(recent_trend) * 0.1 else 'medium'
                    return {
                        'risk_level': risk_level,
                        'confidence': 0.7,  # простая уверенность
                        'predicted_trend': float(slope)
                    }
        
        return {'risk_level': 'low', 'confidence': 0.8}
```

### 2. Cloud-Based Performance Testing
```javascript
import boto3
from botocore.exceptions import ClientError

class CloudPerformanceTesting:
    def __init__(self, cloud_provider='aws'):
        self.provider = cloud_provider
        self.clients = {}
        
        if cloud_provider == 'aws':
            self.clients['lambda'] = boto3.client('lambda')
            self.clients['ec2'] = boto3.client('ec2')
            self.clients['cloudwatch'] = boto3.client('cloudwatch')
    
    def setup_distributed_load_test(self, test_config):
        """Настройка распределенного нагрузочного теста в облаке"""
        if self.provider == 'aws':
            return self._setup_aws_distributed_test(test_config)
        else:
            raise NotImplementedError(f"Cloud provider {self.provider} not supported")
    
    def _setup_aws_distributed_test(self, test_config):
        """Настройка AWS распределенного теста"""
        # Создание Lambda функций для генерации нагрузки
        lambda_functions = []
        
        for i in range(test_config.get('concurrent_zones', 3)):
            function_name = f"load-generator-{i}-{int(time.time())}"
            
            # Код Lambda функции для генерации нагрузки
            lambda_code = f'''
import json
import urllib3

def lambda_handler(event, context):
    http = urllib3.PoolManager()
    target_url = event.get('target_url', '')
    requests_count = event.get('requests_count', 100)
    
    results = []
    for i in range(requests_count):
        try:
            response = http.request('GET', target_url)
            results.append({{
                'request': i,
                'status': response.status,
                'time': response.time_total if hasattr(response, 'time_total') else 0
            }})
        except Exception as e:
            results.append({{
                'request': i,
                'error': str(e),
                'status': 0
            }})
    
    return {{
        'statusCode': 200,
        'body': json.dumps(results)
    }}
'''
            
            try:
                response = self.clients['lambda'].create_function(
                    FunctionName=function_name,
                    Runtime='python3.9',
                    Role=test_config['iam_role'],
                    Handler='lambda_function.lambda_handler',
                    Code={'ZipFile': lambda_code.encode()},
                    Timeout=300,
                    MemorySize=128
                )
                lambda_functions.append(function_name)
            except ClientError as e:
                print(f"Error creating Lambda function: {e}")
        
        return {
            'lambda_functions': lambda_functions,
            'setup_complete': True,
            'zones_count': len(lambda_functions)
        }
    
    def execute_cloud_test(self, test_config):
        """Выполнение теста в облаке"""
        setup_result = self.setup_distributed_load_test(test_config)
        
        if not setup_result['setup_complete']:
            return {'error': 'Setup failed'}
        
        # Асинхронный вызов всех Lambda функций
        import concurrent.futures
        
        results = []
        lambda_client = self.clients['lambda']
        
        with concurrent.futures.ThreadPoolExecutor() as executor:
            futures = []
            
            for func_name in setup_result['lambda_functions']:
                future = executor.submit(
                    lambda_client.invoke,
                    FunctionName=func_name,
                    InvocationType='Event',  # Асинхронный вызов
                    Payload=json.dumps({
                        'target_url': test_config['target_url'],
                        'requests_count': test_config['requests_per_zone']
                    })
                )
                futures.append(future)
            
            for future in concurrent.futures.as_completed(futures):
                try:
                    result = future.result()
                    results.append(result)
                except Exception as e:
                    results.append({'error': str(e)})
        
        return {
            'test_executed': True,
            'lambda_invocations': len(results),
            'results': results
        }
```

## Performance Architecture in Microservices

### 1. Service Mesh for Performance
```yaml
# Пример конфигурации Istio для производительности
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: productpage
spec:
  host: productpage
  trafficPolicy:
    connectionPool:
      tcp:
        maxConnections: 100
        connectTimeout: 30ms
      http:
        http1MaxPendingRequests: 100
        maxRequestsPerConnection: 10
        maxRetries: 3
    outlierDetection:
      consecutiveErrors: 3
      interval: 30s
      baseEjectionTime: 30s
      maxEjectionPercent: 10
---
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: productpage
spec:
  hosts:
  - productpage
  http:
  - route:
    - destination:
        host: productpage
        subset: v1
      weight: 90
    - destination:
        host: productpage
        subset: v2
      weight: 10
    timeout: 5s
    retries:
      attempts: 3
      perTryTimeout: 2s
```

### 2. Performance-Optimized Communication
```javascript
// Оптимизированный клиент для микросервисов
class OptimizedServiceClient {
  constructor(serviceUrl, options = {}) {
    this.serviceUrl = serviceUrl;
    this.timeout = options.timeout || 5000;
    this.retryAttempts = options.retryAttempts || 3;
    this.retryDelay = options.retryDelay || 1000;
    this.circuitBreaker = new PerformanceCircuitBreaker({
      failureThreshold: 5,
      timeout: 60000,
      resetTimeout: 30000
    });
    this.cache = new Map();
    this.cacheTTL = options.cacheTTL || 300000; // 5 минут
  }

  async call(endpoint, method = 'GET', data = null) {
    const cacheKey = `${method}:${endpoint}:${JSON.stringify(data)}`;
    const cached = this.cache.get(cacheKey);

    if (cached && Date.now() - cached.timestamp < this.cacheTTL) {
      return cached.data;
    }

    return await this.circuitBreaker.call(async () => {
      let lastError;

      for (let attempt = 0; attempt <= this.retryAttempts; attempt++) {
        try {
          const response = await this.makeRequest(endpoint, method, data);
          
          // Кэширование успешного ответа
          if (method === 'GET') {
            this.cache.set(cacheKey, {
              data: response,
              timestamp: Date.now()
            });
          }
          
          return response;
        } catch (error) {
          lastError = error;
          
          if (attempt < this.retryAttempts) {
            await this.delay(this.retryDelay * Math.pow(2, attempt)); // exponential backoff
          }
        }
      }

      throw lastError;
    });
  }

  async makeRequest(endpoint, method, data) {
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), this.timeout);

    try {
      const response = await fetch(`${this.serviceUrl}${endpoint}`, {
        method,
        headers: {
          'Content-Type': 'application/json',
        },
        body: data ? JSON.stringify(data) : undefined,
        signal: controller.signal
      });

      clearTimeout(timeoutId);

      if (!response.ok) {
        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
      }

      return await response.json();
    } catch (error) {
      clearTimeout(timeoutId);
      
      if (error.name === 'AbortError') {
        throw new Error('Request timeout');
      }
      
      throw error;
    }
  }

  delay(ms) {
    return new Promise(resolve => setTimeout(resolve, ms));
  }

  clearCache() {
    this.cache.clear();
  }
}
```

## Performance Architecture in Event-Driven Systems

### 1. Optimized Event Processing
```javascript
// Оптимизированный обработчик событий
class OptimizedEventProcessor {
  constructor(options = {}) {
    this.batchSize = options.batchSize || 100;
    this.batchTimeout = options.batchTimeout || 1000; // 1 секунда
    this.maxConcurrency = options.maxConcurrency || 10;
    this.eventQueue = [];
    this.processingQueue = [];
    this.isProcessing = false;
    this.metrics = new MetricsCollector();
  }

  async processEvent(event) {
    this.eventQueue.push(event);
    
    if (this.eventQueue.length >= this.batchSize) {
      this.processBatch();
    } else if (!this.isProcessing) {
      // Запуск таймера для обработки батча
      setTimeout(() => this.processBatch(), this.batchTimeout);
    }
  }

  async processBatch() {
    if (this.eventQueue.length === 0 || this.isProcessing) {
      return;
    }

    this.isProcessing = true;
    const batch = this.eventQueue.splice(0, this.batchSize);
    
    try {
      // Параллельная обработка событий в батче
      const promises = batch.map(event => this.handleEvent(event));
      await Promise.all(promises);
      
      this.metrics.increment('events_processed', batch.length);
    } catch (error) {
      this.metrics.increment('events_failed', batch.length);
      console.error('Error processing event batch:', error);
    } finally {
      this.isProcessing = false;
      
      // Обработка оставшихся событий
      if (this.eventQueue.length > 0) {
        setImmediate(() => this.processBatch());
      }
    }
  }

  async handleEvent(event) {
    this.metrics.startTimer('event_handling');
    
    try {
      // Логика обработки события
      await this.processEventLogic(event);
      this.metrics.increment('event_success');
    } catch (error) {
      this.metrics.increment('event_error');
      console.error(`Error processing event ${event.id}:`, error);
      
      // Повторная отправка в очередь ошибок
      await this.sendToDeadLetterQueue(event, error);
    } finally {
      this.metrics.stopTimer('event_handling');
    }
  }

  async processEventLogic(event) {
    // Реализация логики обработки события
    console.log(`Processing event: ${event.type}`);
    // Здесь будет ваша бизнес-логика
  }

  async sendToDeadLetterQueue(event, error) {
    // Отправка события в очередь ошибок
    console.error(`Sending event ${event.id} to DLQ:`, error);
  }
}
```

## Performance Architecture in API Integration

### 1. Optimized API Client
```javascript
// Оптимизированный клиент для интеграции с API
class OptimizedAPIClient {
  constructor(baseURL, options = {}) {
    this.baseURL = baseURL;
    this.timeout = options.timeout || 10000;
    this.retryAttempts = options.retryAttempts || 3;
    this.cache = new LRUCache(options.cacheSize || 1000);
    this.rateLimiter = new TokenBucketLimiter(options.rateLimit || 100);
    this.metrics = new MetricsCollector();
    this.requestQueue = [];
    this.maxConcurrent = options.maxConcurrent || 10;
    this.activeRequests = 0;
  }

  async request(endpoint, options = {}) {
    const cacheKey = this.getCacheKey(endpoint, options);
    
    // Проверка кэша
    if (options.method === 'GET' && this.cache.has(cacheKey)) {
      this.metrics.increment('cache_hit');
      return this.cache.get(cacheKey);
    }

    // Проверка рейт-лимита
    if (!this.rateLimiter.consume()) {
      throw new Error('Rate limit exceeded');
    }

    this.metrics.startTimer('api_request');
    
    try {
      // Ограничение количества одновременных запросов
      if (this.activeRequests >= this.maxConcurrent) {
        // Добавление в очередь
        return new Promise((resolve, reject) => {
          this.requestQueue.push({ endpoint, options, resolve, reject });
          this.processQueue();
        });
      }

      this.activeRequests++;
      const response = await this.makeRequest(endpoint, options);
      
      // Кэширование GET-запросов
      if (options.method === 'GET') {
        this.cache.set(cacheKey, response);
      }
      
      this.metrics.increment('api_success');
      return response;
    } catch (error) {
      this.metrics.increment('api_error');
      throw error;
    } finally {
      this.activeRequests--;
      this.metrics.stopTimer('api_request');
      this.processQueue(); // Обработка очереди
    }
  }

  async makeRequest(endpoint, options) {
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), this.timeout);

    try {
      const response = await fetch(`${this.baseURL}${endpoint}`, {
        ...options,
        signal: controller.signal
      });

      clearTimeout(timeoutId);

      if (!response.ok) {
        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
      }

      return await response.json();
    } catch (error) {
      clearTimeout(timeoutId);
      throw error;
    }
  }

  getCacheKey(endpoint, options) {
    return `${endpoint}_${JSON.stringify(options)}`;
  }

  processQueue() {
    if (this.requestQueue.length > 0 && this.activeRequests < this.maxConcurrent) {
      const { endpoint, options, resolve, reject } = this.requestQueue.shift();
      
      this.request(endpoint, options)
        .then(resolve)
        .catch(reject);
    }
  }
}
```

## Performance Architecture in Frontend

### 1. Optimized Frontend Architecture
```javascript
// Архитектура оптимизированного фронтенда
class OptimizedFrontendArchitecture {
  constructor(config) {
    this.apiClient = new OptimizedAPIClient(config.apiBaseURL, config.apiOptions);
    this.eventBus = new OptimizedEventBus();
    this.cache = new LRUCache(config.cacheSize || 10000);
    this.performanceObserver = new PerformanceObserver(this.handlePerformanceEntry);
    this.metrics = new MetricsCollector();
    this.resourceLoader = new OptimizedResourceLoader();
    this.stateManager = new OptimizedStateManager();
  }

  async initialize() {
    // Инициализация производительности
    this.performanceObserver.observe({ entryTypes: ['navigation', 'paint', 'measure'] });
    
    // Предзагрузка критических ресурсов
    await this.preloadCriticalResources();
  }

  async preloadCriticalResources() {
    const criticalResources = [
      '/api/user/profile',
      '/api/app/config',
      '/styles/critical.css'
    ];

    await Promise.allSettled(
      criticalResources.map(resource => 
        this.apiClient.request(resource).catch(console.warn)
      )
    );
  }

  handlePerformanceEntry(list) {
    for (const entry of list.getEntries()) {
      if (entry.entryType === 'measure') {
        this.metrics.recordHistogram('custom_measure', entry.duration);
      } else if (entry.entryType === 'paint') {
        this.metrics.setGauge(`paint_${entry.name}`, entry.startTime);
      }
    }
  }

  // Оптимизированный рендеринг
  async renderComponent(componentName, props) {
    const renderStart = performance.now();
    
    try {
      // Использование кэширования для компонентов
      const cacheKey = `component_${componentName}_${JSON.stringify(props)}`;
      let component = this.cache.get(cacheKey);

      if (!component) {
        component = await this.loadComponent(componentName);
        this.cache.set(cacheKey, component);
      }

      const rendered = component.render(props);
      const renderTime = performance.now() - renderStart;
      
      this.metrics.recordHistogram('component_render_time', renderTime);
      return rendered;
    } catch (error) {
      this.metrics.increment('component_render_error');
      throw error;
    }
  }

  async loadComponent(componentName) {
    // Ленивая загрузка компонентов
    return await this.resourceLoader.loadComponent(componentName);
  }

  // Оптимизированное управление состоянием
  setState(newState, callback) {
    this.stateManager.updateState(newState, callback);
  }

  subscribeToStateChanges(listener) {
    return this.stateManager.subscribe(listener);
  }
}
```

## Performance Architecture in CI/CD

### 1. Optimized CI/CD Pipeline
```yaml
# Оптимизированный CI/CD pipeline
name: Optimized CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

env:
  NODE_ENV: test
  CYPRESS_CACHE_FOLDER: ~/.cache/Cypress

jobs:
  build:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        node-version: [16.x, 18.x]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
      with:
        fetch-depth: 0  # Для расчета изменений
    
    - name: Setup Node.js
      uses: actions/setup-node@v3
      with:
        node-version: ${{ matrix.node-version }}
        cache: 'npm'
    
    - name: Cache dependencies
      id: cache-deps
      uses: actions/cache@v3
      with:
        path: |
          **/node_modules
          ~/.cache/Cypress
        key: ${{ runner.os }}-node-${{ matrix.node-version }}-${{ hashFiles('**/package-lock.json') }}
    
    - name: Install dependencies
      if: steps.cache-deps.outputs.cache-hit != 'true'
      run: npm ci
    
    - name: Build application
      run: |
        npm run build
        echo "Build completed at $(date)"
      env:
        NODE_ENV: production
    
    - name: Cache build artifacts
      uses: actions/cache@v3
      with:
        path: dist/
        key: ${{ runner.os }}-build-${{ github.sha }}
    
    - name: Upload build artifacts
      uses: actions/upload-artifact@v3
      with:
        name: build-artifacts
        path: dist/

  test:
    needs: build
    runs-on: ubuntu-latest
    strategy:
      matrix:
        node-version: [18.x]
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Setup Node.js
      uses: actions/setup-node@v3
      with:
        node-version: ${{ matrix.node-version }}
        cache: 'npm'
    
    - name: Cache dependencies
      uses: actions/cache@v3
      with:
        path: |
          **/node_modules
          ~/.cache/Cypress
        key: ${{ runner.os }}-node-${{ matrix.node-version }}-${{ hashFiles('**/package-lock.json') }}
    
    - name: Run unit tests with performance monitoring
      run: |
        npm run test:unit -- --coverage --maxWorkers=2
        echo "Unit tests completed at $(date)"
    
    - name: Run integration tests
      run: |
        npm run test:integration -- --maxWorkers=2
        echo "Integration tests completed at $(date)"
    
    - name: Run performance tests
      run: |
        npm run test:performance
        echo "Performance tests completed at $(date)"
    
    - name: Upload test results
      uses: actions/upload-artifact@v3
      with:
        name: test-results
        path: |
          coverage/
          test-results/

  deploy:
    needs: [build, test]
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    environment: production
    
    steps:
    - name: Download build artifacts
      uses: actions/download-artifact@v3
      with:
        name: build-artifacts
        path: dist/
    
    - name: Deploy to production
      run: |
        # Скрипт деплоя
        echo "Deploying to production at $(date)"
        # deploy commands here