---
aliases: [Инференс в браузере, ML Inference, Model Inference]
tags: [typescript, machine-learning, inference, browser-ml, tensorflowjs, onnx, neural-networks, prediction]
---

# Инференс моделей машинного обучения в браузере

## Введение

Инференс (вывод) - это процесс, при котором обученная модель используется для предсказания на новых данных. В контексте браузера, инференс позволяет запускать предварительно обученные модели непосредственно в веб-приложении, обеспечивая быстрые отклики без необходимости взаимодействия с сервером. TypeScript обеспечивает строгую типизацию, что особенно важно при работе с тензорами и результатами инференса.

## Основы инференса

### Что такое инференс

Инференс - это применение обученной модели к новым данным для получения предсказаний. В отличие от обучения, инференс:
- Не изменяет веса модели
- Обычно быстрее, чем обучение
- Может выполняться на менее мощных устройствах
- Часто требует меньше памяти

### Типы инференса

1. **Пакетный инференс** - обработка нескольких примеров одновременно
2. **Поэлементный инференс** - обработка одного примера за раз
3. **Потоковый инференс** - обработка данных в реальном времени

## Подготовка модели к инференсу

### Загрузка модели для инференса

```typescript
import * as tf from '@tensorflow/tfjs';

// Загрузка Graph Model для оптимизированного инференса
async function loadInferenceModel(modelUrl: string): Promise<tf.GraphModel> {
  try {
    const model = await tf.loadGraphModel(modelUrl);
    console.log('Модель успешно загружена для инференса');
    return model;
  } catch (error) {
    console.error('Ошибка загрузки модели:', error);
    throw error;
  }
}

// Загрузка Layers Model с возможностью последующего инференса
async function loadTrainableModel(modelUrl: string): Promise<tf.LayersModel> {
  try {
    const model = await tf.loadLayersModel(modelUrl);
    console.log('Layers модель успешно загружена');
    return model;
  } catch (error) {
    console.error('Ошибка загрузки Layers модели:', error);
    throw error;
  }
}
```

### Валидация модели

```typescript
// Класс для валидации модели перед инференсом
class ModelValidator {
  static validateForInference(model: tf.GraphModel | tf.LayersModel): ValidationResult {
    const result: ValidationResult = {
      isValid: true,
      errors: [],
      warnings: [],
      inputShape: null,
      outputShape: null
    };
    
    try {
      // Проверка входной формы
      if (model.inputs && model.inputs.length > 0) {
        const input = model.inputs[0] as tf.SymbolicTensor;
        result.inputShape = input.shape;
      } else {
        result.isValid = false;
        result.errors.push('Модель не имеет определенных входов');
      }
      
      // Проверка выходной формы
      if (model.outputs && model.outputs.length > 0) {
        const output = model.outputs[0] as tf.SymbolicTensor;
        result.outputShape = output.shape;
      } else {
        result.isValid = false;
        result.errors.push('Модель не имеет определенных выходов');
      }
      
      // Проверка, что модель готова к инференсу
      if ('predict' in model) {
        // LayersModel
        result.modelType = 'LayersModel';
      } else if ('executeAsync' in model) {
        // GraphModel
        result.modelType = 'GraphModel';
      } else {
        result.isValid = false;
        result.errors.push('Неизвестный тип модели');
      }
      
      // Дополнительные проверки
      if (result.inputShape && result.inputShape.some(dim => dim === -1)) {
        result.warnings.push('Модель имеет неопределенные размерности - могут возникнуть проблемы с инференсом');
      }
      
    } catch (error) {
      result.isValid = false;
      result.errors.push(`Ошибка валидации: ${error.message}`);
    }
    
    return result;
  }
}

interface ValidationResult {
  isValid: boolean;
  errors: string[];
  warnings: string[];
  inputShape: number[] | null;
  outputShape: number[] | null;
  modelType?: 'LayersModel' | 'GraphModel';
}
```

## Выполнение инференса

### Базовый инференс с LayersModel

```typescript
// Класс для выполнения инференса с типизацией
class InferenceEngine {
  private model: tf.LayersModel | tf.GraphModel;
  private inputShape: number[];
  private outputShape: number[];
  
  constructor(model: tf.LayersModel | tf.GraphModel) {
    this.model = model;
    
    // Получение форм входа и выхода
    if (model.inputs && model.inputs.length > 0) {
      const input = model.inputs[0] as tf.SymbolicTensor;
      this.inputShape = input.shape;
    } else {
      throw new Error('Модель не имеет определенного входа');
    }
    
    if (model.outputs && model.outputs.length > 0) {
      const output = model.outputs[0] as tf.SymbolicTensor;
      this.outputShape = output.shape;
    } else {
      throw new Error('Модель не имеет определенного выхода');
    }
  }
  
  // Выполнение инференса с валидацией входных данных
  async predict(inputData: number[] | number[][]): Promise<InferenceResult> {
    // Преобразование данных в тензор
    let inputTensor: tf.Tensor;
    
    if (Array.isArray(inputData[0])) {
      // Это 2D массив (несколько примеров)
      inputTensor = tf.tensor2d(inputData as number[][], [inputData.length, (inputData[0] as number[]).length]);
    } else {
      // Это 1D массив (один пример)
      inputTensor = tf.tensor1d(inputData as number[]);
      
      // Добавление размерности батча, если необходимо
      if (this.inputShape.length === 2) {
        inputTensor = inputTensor.expandDims(0);
      }
    }
    
    // Проверка соответствия формы
    if (!this.validateInputShape(inputTensor.shape)) {
      inputTensor.dispose();
      throw new Error(`Неверная форма входных данных. Ожидается: [${this.inputShape}], получено: [${inputTensor.shape}]`);
    }
    
    // Выполнение инференса
    let prediction: tf.Tensor;
    
    if ('predict' in this.model) {
      // LayersModel
      prediction = this.model.predict(inputTensor) as tf.Tensor;
    } else {
      // GraphModel
      prediction = await (this.model as tf.GraphModel).executeAsync(inputTensor);
    }
    
    // Получение данных результата
    const predictionData = await prediction.data();
    
    // Создание результата
    const result: InferenceResult = {
      predictions: Array.from(predictionData),
      inputShape: inputTensor.shape,
      outputShape: prediction.shape,
      executionTime: 0 // будет рассчитано ниже
    };
    
    // Освобождение памяти
    inputTensor.dispose();
    prediction.dispose();
    
    return result;
  }
  
  private validateInputShape(inputShape: number[]): boolean {
    // Проверяем, соответствует ли входная форма ожидаемой
    if (inputShape.length !== this.inputShape.length) {
      return false;
    }
    
    for (let i = 0; i < this.inputShape.length; i++) {
      if (this.inputShape[i] !== -1 && this.inputShape[i] !== inputShape[i]) {
        return false;
      }
    }
    
    return true;
  }
  
  // Более эффективный метод для пакетного инференса
  async predictBatch(inputs: tf.Tensor): Promise<tf.Tensor> {
    if ('predict' in this.model) {
      return this.model.predict(inputs) as tf.Tensor;
    } else {
      return await (this.model as tf.GraphModel).executeAsync(inputs);
    }
  }
}

interface InferenceResult {
  predictions: number[];
  inputShape: number[];
  outputShape: number[];
  executionTime: number;
}
```

### Инференс с оптимизацией производительности

```typescript
// Класс для оптимизированного инференса
class OptimizedInferenceEngine {
  private model: tf.GraphModel;
  private warmupExecuted: boolean;
  
  constructor(model: tf.GraphModel) {
    this.model = model;
    this.warmupExecuted = false;
  }
  
  // Выполнение прогрева модели
  async warmup(inputShape: number[]): Promise<void> {
    if (this.warmupExecuted) {
      return;
    }
    
    // Создание тензора с нулевыми значениями для прогрева
    const dummyInput = tf.zeros(inputShape);
    
    // Выполнение инференса для прогрева
    const prediction = await this.model.executeAsync(dummyInput);
    
    // Освобождение памяти
    dummyInput.dispose();
    prediction.dispose();
    
    this.warmupExecuted = true;
    console.log('Модель выполнено прогревание для оптимизации производительности');
  }
  
  // Выполнение инференса с измерением времени
  async predictWithTiming(inputTensor: tf.Tensor): Promise<TimedInferenceResult> {
    const startTime = performance.now();
    
    const prediction = await this.model.executeAsync(inputTensor);
    const outputData = await prediction.data();
    
    const endTime = performance.now();
    const executionTime = endTime - startTime;
    
    // Освобождение памяти
    prediction.dispose();
    
    return {
      predictions: Array.from(outputData),
      executionTime: executionTime,
      inputShape: inputTensor.shape,
      outputShape: [outputData.length] // предполагаем 1D результат для простоты
    };
  }
  
  // Выполнение инференса с tf.tidy для автоматической очистки
  predictWithCleanup(inputData: number[]): Promise<TimedInferenceResult> {
    return tf.tidy(() => {
      const inputTensor = tf.tensor1d(inputData);
      return this.predictWithTiming(inputTensor);
    });
  }
}

interface TimedInferenceResult extends InferenceResult {
  executionTime: number;
}
```

## Инференс для различных типов моделей

### Инференс для моделей компьютерного зрения

```typescript
// Класс для инференса моделей компьютерного зрения
class VisionInference {
  private model: tf.GraphModel;
  private inputSize: [number, number]; // [height, width]
  private mean: [number, number, number]; // [R, G, B]
  private std: [number, number, number]; // [R, G, B]
  
  constructor(
    model: tf.GraphModel, 
    inputSize: [number, number] = [224, 224],
    mean: [number, number, number] = [0, 0, 0],
    std: [number, number, number] = [1, 1, 1]
  ) {
    this.model = model;
    this.inputSize = inputSize;
    this.mean = mean;
    this.std = std;
  }
  
  // Подготовка изображения для инференса
  preprocessImage(imageElement: HTMLImageElement): tf.Tensor4D {
    return tf.tidy(() => {
      // Преобразование изображения в тензор
      let tensor = tf.browser.fromPixels(imageElement);
      
      // Изменение размера изображения
      tensor = tf.image.resizeBilinear(tensor, this.inputSize);
      
      // Преобразование в формат float32 и нормализация
      const normalized = tensor.cast('float32')
        .sub(this.mean.map(val => tf.scalar(val)))
        .div(this.std.map(val => tf.scalar(val)));
      
      // Добавление размерности батча
      return normalized.expandDims(0) as tf.Tensor4D;
    });
  }
  
  // Выполнение инференса классификации изображений
  async classifyImage(imageElement: HTMLImageElement, labels: string[]): Promise<ClassificationResult[]> {
    const preprocessed = this.preprocessImage(imageElement);
    
    const startTime = performance.now();
    const prediction = await this.model.executeAsync(preprocessed) as tf.Tensor2D;
    const executionTime = performance.now() - startTime;
    
    const probabilities = await prediction.data();
    
    // Преобразование в результаты классификации
    const results = this.getTopClasses(probabilities, labels, 5);
    
    // Освобождение памяти
    preprocessed.dispose();
    prediction.dispose();
    
    return results.map((result, index) => ({
      ...result,
      executionTime: index === 0 ? executionTime : 0 // время выполнения только для первого результата
    }));
  }
  
  // Получение топ-N классов
  private getTopClasses(probabilities: Float32Array, labels: string[], topK: number): Omit<ClassificationResult, 'executionTime'>[] {
    const probsAndIndices = Array.from(probabilities)
      .map((prob, index) => ({ prob, index }))
      .sort((a, b) => b.prob - a.prob)
      .slice(0, topK);
    
    return probsAndIndices.map(({ prob, index }) => ({
      label: labels[index],
      probability: prob,
      classIndex: index
    }));
  }
  
  // Выполнение инференса для задачи обнаружения объектов
  async detectObjects(imageElement: HTMLImageElement): Promise<ObjectDetectionResult[]> {
    const preprocessed = this.preprocessImage(imageElement);
    
    const startTime = performance.now();
    const prediction = await this.model.executeAsync(preprocessed);
    const executionTime = performance.now() - startTime;
    
    // В зависимости от модели, структура выходных данных может отличаться
    // Ниже приведен общий пример для YOLO-подобной модели
    
    let boxes: tf.Tensor2D, scores: tf.Tensor1D, classes: tf.Tensor1D;
    
    if (Array.isArray(prediction)) {
      // Предполагаем, что модель возвращает [boxes, scores, classes]
      [boxes, scores, classes] = prediction as [tf.Tensor2D, tf.Tensor1D, tf.Tensor1D];
    } else {
      // Если модель возвращает один тензор, нужно интерпретировать его структуру
      throw new Error('Для задачи обнаружения объектов требуется модель, возвращающая несколько тензоров');
    }
    
    const [boxesData, scoresData, classesData] = await Promise.all([
      boxes.data(),
      scores.data(),
      classes.data()
    ]);
    
    // Преобразование результатов в формат обнаружения объектов
    const detections: ObjectDetectionResult[] = [];
    const imageWidth = imageElement.width;
    const imageHeight = imageElement.height;
    
    for (let i = 0; i < scoresData.length; i++) {
      if (scoresData[i] > 0.5) { // порог уверенности
        const [yMin, xMin, yMax, xMax] = Array.from(boxesData.slice(i * 4, (i + 1) * 4));
        
        detections.push({
          className: `class_${classesData[i]}`,
          confidence: scoresData[i],
          bbox: [
            xMin * imageWidth,   // x
            yMin * imageHeight,  // y
            (xMax - xMin) * imageWidth,   // width
            (yMax - yMin) * imageHeight   // height
          ],
          executionTime: i === 0 ? executionTime : 0
        });
      }
    }
    
    // Освобождение памяти
    preprocessed.dispose();
    boxes.dispose();
    scores.dispose();
    classes.dispose();
    
    // Применение NMS (Non-Maximum Suppression) для фильтрации дубликатов
    return this.applyNMS(detections, 0.5);
  }
  
  // Применение NMS для фильтрации дубликатов
  private applyNMS(detections: ObjectDetectionResult[], iouThreshold: number): ObjectDetectionResult[] {
    // Реализация NMS (упрощенная версия)
    const filteredDetections = [...detections];
    filteredDetections.sort((a, b) => b.confidence - a.confidence);
    
    const result: ObjectDetectionResult[] = [];
    const used = new Array(filteredDetections.length).fill(false);
    
    for (let i = 0; i < filteredDetections.length; i++) {
      if (used[i]) continue;
      
      result.push(filteredDetections[i]);
      
      for (let j = i + 1; j < filteredDetections.length; j++) {
        if (used[j]) continue;
        
        const iou = this.calculateIoU(filteredDetections[i].bbox, filteredDetections[j].bbox);
        if (iou > iouThreshold) {
          used[j] = true;
        }
      }
    }
    
    return result;
  }
  
  // Расчет IoU (Intersection over Union)
  private calculateIoU(bbox1: [number, number, number, number], bbox2: [number, number, number, number]): number {
    const [x1, y1, w1, h1] = bbox1;
    const [x2, y2, w2, h2] = bbox2;
    
    const xLeft = Math.max(x1, x2);
    const yTop = Math.max(y1, y2);
    const xRight = Math.min(x1 + w1, x2 + w2);
    const yBottom = Math.min(y1 + h1, y2 + h2);
    
    if (xRight < xLeft || yBottom < yTop) return 0;
    
    const intersectionArea = (xRight - xLeft) * (yBottom - yTop);
    const bbox1Area = w1 * h1;
    const bbox2Area = w2 * h2;
    
    return intersectionArea / (bbox1Area + bbox2Area - intersectionArea);
  }
}

interface ClassificationResult {
  label: string;
  probability: number;
  classIndex: number;
  executionTime: number;
}

interface ObjectDetectionResult {
  className: string;
  confidence: number;
  bbox: [number, number, number, number]; // [x, y, width, height]
  executionTime: number;
}
```

### Инференс для моделей обработки естественного языка

```typescript
// Класс для инференса NLP моделей
class NLPInference {
  private model: tf.GraphModel;
  private tokenizer: NLPTokenizer;
  private maxLength: number;
  
  constructor(model: tf.GraphModel, maxLength: number = 128) {
    this.model = model;
    this.tokenizer = new NLPTokenizer();
    this.maxLength = maxLength;
  }
  
  // Выполнение инференса для задачи классификации текста
  async classifyText(text: string, labels: string[]): Promise<TextClassificationResult> {
    // Токенизация текста
    const tokens = this.tokenizer.tokenize(text, this.maxLength);
    const inputTensor = tf.tensor2d([tokens], [1, tokens.length]);
    
    const startTime = performance.now();
    const prediction = await this.model.executeAsync(inputTensor) as tf.Tensor2D;
    const executionTime = performance.now() - startTime;
    
    const probabilities = await prediction.data();
    
    // Определение результата
    const maxIndex = probabilities.indexOf(Math.max(...probabilities));
    const result: TextClassificationResult = {
      label: labels[maxIndex],
      confidence: probabilities[maxIndex],
      allProbabilities: Array.from(probabilities),
      executionTime
    };
    
    // Освобождение памяти
    inputTensor.dispose();
    prediction.dispose();
    
    return result;
  }
  
  // Выполнение инференса для задачи генерации текста (упрощенный пример)
  async generateText(prompt: string, maxLength: number = 50): Promise<string> {
    let generated = prompt;
    
    for (let i = 0; i < maxLength; i++) {
      const tokens = this.tokenizer.tokenize(generated, this.maxLength);
      const inputTensor = tf.tensor2d([tokens], [1, tokens.length]);
      
      const prediction = await this.model.executeAsync(inputTensor) as tf.Tensor2D;
      const probabilities = await prediction.data();
      
      // Выбор следующего токена (самый вероятный)
      const nextTokenId = probabilities.indexOf(Math.max(...probabilities));
      const nextToken = this.tokenizer.decodeToken(nextTokenId);
      
      if (nextToken === '[END]' || nextToken === '[PAD]') {
        break;
      }
      
      generated += ' ' + nextToken;
      
      // Освобождение памяти
      inputTensor.dispose();
      prediction.dispose();
    }
    
    return generated.substring(prompt.length).trim();
  }
}

// Простой токенизатор для NLP
class NLPTokenizer {
  private vocab: Map<string, number>;
  private reverseVocab: Map<number, string>;
  
  constructor() {
    // В реальном приложении словарь загружается из файла модели
    this.vocab = new Map([
      ['[PAD]', 0],
      ['[UNK]', 1],
      ['[CLS]', 2],
      ['[SEP]', 3],
      ['[MASK]', 4],
      ['the', 5],
      ['a', 6],
      ['an', 7],
      ['and', 8],
      ['or', 9],
      ['but', 10]
    ]);
    
    this.reverseVocab = new Map(Array.from(this.vocab.entries()).map(([key, value]) => [value, key]));
  }
  
  tokenize(text: string, maxLength: number): number[] {
    const tokens = text.toLowerCase().split(/\s+/).filter(token => token.length > 0);
    const tokenIds = tokens.map(token => this.vocab.get(token) || 1); // 1 для [UNK]
    
    // Добавление специальных токенов
    tokenIds.unshift(2); // [CLS]
    tokenIds.push(3); // [SEP]
    
    // Паддинг или усечение
    if (tokenIds.length > maxLength) {
      return tokenIds.slice(0, maxLength);
    } else {
      return [...tokenIds, ...Array(maxLength - tokenIds.length).fill(0)];
    }
  }
  
  decodeToken(tokenId: number): string {
    return this.reverseVocab.get(tokenId) || '[UNK]';
  }
}

interface TextClassificationResult {
  label: string;
  confidence: number;
  allProbabilities: number[];
  executionTime: number;
}
```

## Оптимизация инференса

### Использование разных backend для инференса

```typescript
// Класс для выбора оптимального backend
class BackendOptimizer {
  static async selectBestBackend(): Promise<string> {
    const backends = ['webgl', 'wasm', 'cpu'];
    const testInputs: Record<string, tf.Tensor> = {};
    
    // Подготовка тестовых данных для каждого backend
    for (const backend of backends) {
      try {
        await tf.setBackend(backend);
        await tf.ready();
        
        // Создание простого тестового тензора
        testInputs[backend] = tf.randomNormal([1, 100]);
      } catch (e) {
        console.log(`Backend ${backend} недоступен:`, e);
      }
    }
    
    let bestBackend = 'cpu'; // CPU как резервный вариант
    let bestTime = Infinity;
    
    for (const backend of Object.keys(testInputs)) {
      try {
        await tf.setBackend(backend);
        
        // Тестирование производительности
        const startTime = performance.now();
        
        for (let i = 0; i < 10; i++) { // 10 итераций для усреднения
          const result = tf.matMul(testInputs[backend], testInputs[backend].transpose());
          result.dispose();
        }
        
        const endTime = performance.now();
        const avgTime = (endTime - startTime) / 10;
        
        console.log(`${backend} среднее время: ${avgTime.toFixed(2)}ms`);
        
        if (avgTime < bestTime) {
          bestTime = avgTime;
          bestBackend = backend;
        }
      } catch (e) {
        console.error(`Ошибка тестирования backend ${backend}:`, e);
      }
    }
    
    // Установка лучшего backend
    await tf.setBackend(bestBackend);
    await tf.ready();
    
    console.log(`Выбран оптимальный backend: ${bestBackend}`);
    
    // Очистка тестовых тензоров
    Object.values(testInputs).forEach(tensor => tensor.dispose());
    
    return bestBackend;
  }
}
```

### Кэширование результатов инференса

```typescript
// Класс для кэширования результатов инференса
class InferenceCache {
  private cache: Map<string, InferenceResult>;
  private maxSize: number;
  
  constructor(maxSize: number = 100) {
    this.cache = new Map();
    this.maxSize = maxSize;
  }
  
  // Создание ключа для кэширования на основе входных данных
  private createKey(inputData: number[], modelSignature: string): string {
    // Хэширование входных данных и подписи модели для создания уникального ключа
    const inputHash = this.simpleHash(inputData.join(','));
    return `${modelSignature}_${inputHash}`;
  }
  
  private simpleHash(str: string): string {
    let hash = 0;
    for (let i = 0; i < str.length; i++) {
      const char = str.charCodeAt(i);
      hash = ((hash << 5) - hash) + char;
      hash |= 0; // Преобразование в 32-битное целое
    }
    return hash.toString();
  }
  
  // Получение результата из кэша
  get(key: string): InferenceResult | null {
    return this.cache.get(key) || null;
  }
  
  // Сохранение результата в кэш
  set(key: string, result: InferenceResult): void {
    if (this.cache.size >= this.maxSize) {
      // Удаление старейшего элемента (простая реализация)
      const firstKey = this.cache.keys().next().value;
      this.cache.delete(firstKey);
    }
    
    this.cache.set(key, result);
  }
  
  // Проверка, есть ли результат в кэше
  has(key: string): boolean {
    return this.cache.has(key);
  }
  
  // Очистка кэша
  clear(): void {
    this.cache.clear();
  }
  
  // Получение размера кэша
  size(): number {
    return this.cache.size;
  }
}

// Инференс-движок с кэшированием
class CachedInferenceEngine extends InferenceEngine {
  private cache: InferenceCache;
  private modelSignature: string;
  
  constructor(model: tf.LayersModel | tf.GraphModel, cacheSize: number = 100) {
    super(model);
    this.cache = new InferenceCache(cacheSize);
    
    // Создание подписи модели на основе архитектуры
    this.modelSignature = this.generateModelSignature(model);
  }
  
  private generateModelSignature(model: tf.LayersModel | tf.GraphModel): string {
    if ('layers' in model) {
      // Для LayersModel
      return model.layers.map(layer => layer.getClassName()).join('-');
    } else {
      // Для GraphModel - используем URL или другую идентификацию
      return 'GraphModel';
    }
  }
  
  async predict(inputData: number[] | number[][]): Promise<InferenceResult> {
    // Создание ключа для кэширования
    let inputArray: number[];
    if (Array.isArray(inputData[0])) {
      inputArray = (inputData as number[][]).flat();
    } else {
      inputArray = inputData as number[];
    }
    
    const key = this.cache.createKey(inputArray, this.modelSignature);
    
    // Проверка наличия в кэше
    const cachedResult = this.cache.get(key);
    if (cachedResult) {
      console.log('Результат взят из кэша');
      return cachedResult;
    }
    
    // Выполнение инференса
    const result = await super.predict(inputData);
    
    // Сохранение в кэш
    this.cache.set(key, result);
    
    return result;
  }
}
```

## Практические примеры

### Пример: Реализация системы рекомендаций в браузере

```typescript
// Класс для инференса модели рекомендаций
class RecommendationInference {
  private model: tf.GraphModel;
  private userFeaturesSize: number;
  private itemFeaturesSize: number;
  
  constructor(model: tf.GraphModel, userFeaturesSize: number, itemFeaturesSize: number) {
    this.model = model;
    this.userFeaturesSize = userFeaturesSize;
    this.itemFeaturesSize = itemFeaturesSize;
  }
  
  // Получение рекомендаций для пользователя
  async getRecommendations(
    userFeatures: number[], 
    itemFeaturesList: number[][],
    topK: number = 10
  ): Promise<Recommendation[]> {
    if (userFeatures.length !== this.userFeaturesSize) {
      throw new Error(`Неверный размер пользовательских признаков. Ожидается: ${this.userFeaturesSize}, получено: ${userFeatures.length}`);
    }
    
    // Подготовка входных данных
    const inputs = itemFeaturesList.map(itemFeatures => {
      if (itemFeatures.length !== this.itemFeaturesSize) {
        throw new Error(`Неверный размер признаков элемента. Ожидается: ${this.itemFeaturesSize}, получено: ${itemFeatures.length}`);
      }
      return [...userFeatures, ...itemFeatures]; // объединение признаков пользователя и элемента
    });
    
    const inputTensor = tf.tensor2d(inputs, [inputs.length, this.userFeaturesSize + this.itemFeaturesSize]);
    
    const startTime = performance.now();
    const prediction = await this.model.executeAsync(inputTensor) as tf.Tensor2D;
    const executionTime = performance.now() - startTime;
    
    const probabilities = await prediction.data();
    
    // Создание списка рекомендаций
    const recommendations: Recommendation[] = itemFeaturesList.map((itemFeatures, index) => ({
      itemId: index.toString(), // в реальном приложении будет реальный ID
      relevanceScore: probabilities[index],
      itemFeatures,
      executionTime: index === 0 ? executionTime : 0
    }));
    
    // Сортировка по релевантности и возврат топ-K
    recommendations.sort((a, b) => b.relevanceScore - a.relevanceScore);
    
    // Освобождение памяти
    inputTensor.dispose();
    prediction.dispose();
    
    return recommendations.slice(0, topK);
  }
}

interface Recommendation {
  itemId: string;
  relevanceScore: number;
  itemFeatures: number[];
  executionTime: number;
}
```

### Пример: Инференс для распознавания эмоций по изображению лица

```typescript
// Класс для инференса модели распознавания эмоций
class EmotionRecognitionInference extends VisionInference {
  private emotionLabels: string[];
  
  constructor(model: tf.GraphModel, emotionLabels: string[] = ['neutral', 'happiness', 'surprise', 'sadness', 'anger', 'disgust', 'fear']) {
    super(model, [96, 96]); // для моделей распознавания эмоций часто используется 96x96
    this.emotionLabels = emotionLabels;
  }
  
  async recognizeEmotion(faceImage: HTMLImageElement): Promise<EmotionRecognitionResult> {
    const preprocessed = this.preprocessImage(faceImage);
    
    const startTime = performance.now();
    const prediction = await this.model.executeAsync(preprocessed) as tf.Tensor2D;
    const executionTime = performance.now() - startTime;
    
    const probabilities = await prediction.data();
    
    // Определение эмоции с наибольшей вероятностью
    const maxIndex = probabilities.indexOf(Math.max(...probabilities));
    
    const result: EmotionRecognitionResult = {
      dominantEmotion: this.emotionLabels[maxIndex],
      confidence: probabilities[maxIndex],
      emotionProbabilities: this.emotionLabels.map((label, index) => ({
        emotion: label,
        probability: probabilities[index]
      })),
      executionTime
    };
    
    // Освобождение памяти
    preprocessed.dispose();
    prediction.dispose();
    
    return result;
  }
}

interface EmotionRecognitionResult {
  dominantEmotion: string;
  confidence: number;
  emotionProbabilities: {
    emotion: string;
    probability: number;
  }[];
  executionTime: number;
}
```

## Обработка ошибок и отладка

### Обработка ошибок инференса

```typescript
// Класс для обработки ошибок инференса
class InferenceErrorHandler {
  static handleInferenceError(error: any, context: string = ''): InferenceError {
    const inferenceError: InferenceError = {
      type: 'unknown',
      message: error.message || 'Неизвестная ошибка инференса',
      context,
      timestamp: new Date(),
      stack: error.stack
    };
    
    // Классификация ошибок
    if (error.message.includes('OOM') || error.message.includes('out of memory')) {
      inferenceError.type = 'out_of_memory';
    } else if (error.message.includes('invalid input')) {
      inferenceError.type = 'invalid_input';
    } else if (error.message.includes('timeout')) {
      inferenceError.type = 'timeout';
    } else if (error.message.includes('backend')) {
      inferenceError.type = 'backend_error';
    }
    
    console.error(`Ошибка инференса (${inferenceError.type}):`, inferenceError.message);
    
    return inferenceError;
  }
}

interface InferenceError {
  type: 'out_of_memory' | 'invalid_input' | 'timeout' | 'backend_error' | 'unknown';
  message: string;
  context: string;
  timestamp: Date;
  stack?: string;
}
```

## Заключение

Инференс моделей машинного обучения в браузере позволяет создавать мощные и интерактивные веб-приложения, которые могут обрабатывать данные локально. TypeScript обеспечивает строгую типизацию, что делает разработку более надежной и предсказуемой, особенно при работе со сложными структурами данных, какими являются тензоры и результаты инференса.

## См. также

- [[TensorFlow-js]]
- [[Модели-в-браузере]]
- [[Обучение-в-браузере]]
- [[ONNX-js]]
- [[Оптимизация-производительности-в-браузере]]