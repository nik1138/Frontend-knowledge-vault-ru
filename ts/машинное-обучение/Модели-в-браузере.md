---
aliases: [Модели в браузере, ML в браузере, Browser ML]
tags: [typescript, machine-learning, browser-ml, tensorflowjs, onnx, webml, neural-networks]
---

# Модели машинного обучения в браузере

## Введение

Запуск моделей машинного обучения непосредственно в браузере открывает новые возможности для интерактивных веб-приложений. Это позволяет обрабатывать данные локально, обеспечивая конфиденциальность и снижая задержки. TypeScript предоставляет строгую типизацию, что делает разработку более надежной.

## Преимущества запуска моделей в браузере

### Конфиденциальность данных
- Данные пользователя не покидают устройство
- Возможность обработки чувствительной информации локально
- Снижение рисков утечки данных

### Производительность
- Отсутствие задержек при передаче данных на сервер
- Использование GPU через WebGL для ускорения вычислений
- Локальная обработка без необходимости подключения к интернету

### Масштабируемость
- Нет необходимости в серверной инфраструктуре для инференса
- Уменьшение нагрузки на серверы
- Возможность запуска на любом устройстве с браузером

## Поддерживаемые форматы моделей

### TensorFlow.js Layers Model
- Наиболее распространенный формат для TensorFlow.js
- Поддержка как обученных, так и обучаемых моделей
- Возможность сохранения и загрузки через JSON и бинарные файлы

```typescript
import * as tf from '@tensorflow/tfjs';

// Загрузка модели из URL
const model = await tf.loadLayersModel('https://example.com/model.json');

// Сохранение модели
await model.save('localstorage://my-model');
```

### TensorFlow.js Graph Model
- Оптимизированный формат для инференса
- Меньший размер по сравнению с Layers Model
- Не поддерживает обучение в браузере

```typescript
import * as tf from '@tensorflow/tfjs';

// Загрузка Graph Model
const model = await tf.loadGraphModel('https://example.com/model.json');
```

### ONNX
- Кроссплатформенный формат для представления моделей
- Поддержка моделей из различных фреймворков (PyTorch, TensorFlow, scikit-learn)
- Используется через ONNX Runtime Web

```typescript
import * as ort from 'onnxruntime-web';

// Загрузка ONNX модели
const session = await ort.InferenceSession.create('./model.onnx');
```

## Подготовка моделей для браузера

### Конвертация моделей TensorFlow

```bash
# Конвертация SavedModel в TensorFlow.js формат
tensorflowjs_converter \
    --input_format=tf_saved_model \
    --output_format=tfjs_layers_model \
    /path/to/saved_model \
    /path/to/web_model
```

### Оптимизация моделей

```typescript
import * as tf from '@tensorflow/tfjs';

// Квантование модели для уменьшения размера
async function quantizeModel(modelPath: string): Promise<void> {
  const model = await tf.loadLayersModel(modelPath);
  
  // Сохранение модели с квантованием
  await model.save('http://localhost:8000/quantized-model', {
    includeOptimizer: false,
    format: 'tfjs_layers_model',
    weightsManifest: [{
      paths: ['./model.weights.bin'],
      weights: model.layers.flatMap(layer => 
        layer.getWeights().map(weight => weight.dataSync())
      )
    }]
  });
}
```

## Загрузка и управление моделями

### Класс для управления моделями

```typescript
interface ModelInfo {
  name: string;
  url: string;
  loaded: boolean;
  size?: number;
  inputShape: number[];
  outputShape: number[];
}

class ModelManager {
  private models: Map<string, tf.LayersModel | tf.GraphModel>;
  private modelInfo: Map<string, ModelInfo>;
  
  constructor() {
    this.models = new Map();
    this.modelInfo = new Map();
  }
  
  async loadModel(name: string, url: string, type: 'layers' | 'graph' = 'layers'): Promise<void> {
    let model: tf.LayersModel | tf.GraphModel;
    
    if (type === 'layers') {
      model = await tf.loadLayersModel(url);
    } else {
      model = await tf.loadGraphModel(url);
    }
    
    this.models.set(name, model);
    
    // Получение информации о модели
    const info: ModelInfo = {
      name,
      url,
      loaded: true,
      inputShape: (model.inputs[0] as tf.SymbolicTensor).shape,
      outputShape: (model.outputs[0] as tf.SymbolicTensor).shape
    };
    
    this.modelInfo.set(name, info);
    console.log(`Модель ${name} загружена`);
  }
  
  getModel(name: string): tf.LayersModel | tf.GraphModel | undefined {
    return this.models.get(name);
  }
  
  getModelInfo(name: string): ModelInfo | undefined {
    return this.modelInfo.get(name);
  }
  
  async disposeModel(name: string): Promise<void> {
    const model = this.models.get(name);
    if (model) {
      model.dispose();
      this.models.delete(name);
      this.modelInfo.delete(name);
      console.log(`Модель ${name} очищена`);
    }
  }
  
  listModels(): string[] {
    return Array.from(this.models.keys());
  }
}
```

## Оптимизация производительности

### Выбор backend

```typescript
// Проверка поддерживаемых backend
function checkBackendSupport(): void {
  console.log('Доступные backend:', tf.getBackend());
  
  // Проверка поддержки WebGL
  const webglIsSupported = tf.webgl.isWebGLSupported();
  console.log('WebGL поддерживается:', webglIsSupported);
  
  // Установка backend
  if (webglIsSupported) {
    tf.setBackend('webgl');
    console.log('Установлен backend: webgl');
  } else {
    tf.setBackend('cpu');
    console.log('Установлен backend: cpu');
  }
}

// Адаптивный выбор backend
async function adaptiveBackend(): Promise<void> {
  const backends = ['webgl', 'wasm', 'cpu'];
  
  for (const backend of backends) {
    try {
      await tf.setBackend(backend);
      await tf.ready();
      console.log(`Успешно установлен backend: ${backend}`);
      break;
    } catch (e) {
      console.log(`Backend ${backend} недоступен:`, e);
    }
  }
}
```

### Управление памятью

```typescript
// Класс для мониторинга и управления памятью
class MemoryManager {
  private initialMemory: number;
  
  constructor() {
    this.initialMemory = this.getUsedMemory();
  }
  
  getUsedMemory(): number {
    if ((performance as any).memory) {
      return (performance as any).memory.usedJSHeapSize;
    }
    return 0;
  }
  
  logMemoryUsage(): void {
    const current = this.getUsedMemory();
    const diff = current - this.initialMemory;
    console.log(`Использование памяти: ${(current / 1024 / 1024).toFixed(2)} MB (${diff > 0 ? '+' : ''}${(diff / 1024 / 1024).toFixed(2)} MB)`);
  }
  
  // Использование tf.tidy для автоматической очистки тензоров
  executeWithCleanup<T>(fn: () => T): T {
    return tf.tidy(fn);
  }
}

// Использование MemoryManager
const memoryManager = new MemoryManager();
memoryManager.logMemoryUsage();
```

## Практические примеры

### Пример: Классификация изображений

```typescript
class ImageClassifier {
  private model: tf.GraphModel;
  private labels: string[];
  private modelManager: ModelManager;
  
  constructor(labels: string[]) {
    this.labels = labels;
    this.modelManager = new ModelManager();
  }
  
  async loadModel(modelUrl: string): Promise<void> {
    await this.modelManager.loadModel('classifier', modelUrl, 'graph');
    this.model = this.modelManager.getModel('classifier') as tf.GraphModel;
  }
  
  async classifyImage(imageElement: HTMLImageElement): Promise<ClassificationResult[]> {
    // Предварительная обработка изображения
    const tensor = this.preprocessImage(imageElement);
    
    // Выполнение инференса
    const prediction = this.model.predict(tensor) as tf.Tensor;
    
    // Преобразование результата
    const probabilities = await prediction.data();
    const results = this.getTopClasses(probabilities, 5);
    
    // Освобождение памяти
    tensor.dispose();
    prediction.dispose();
    
    return results;
  }
  
  private preprocessImage(image: HTMLImageElement): tf.Tensor3D {
    // Преобразование изображения в тензор
    let tensor = tf.browser.fromPixels(image);
    
    // Изменение размера до 224x224 (для MobileNet)
    tensor = tf.image.resizeBilinear(tensor, [224, 224]);
    
    // Нормализация значений пикселей
    tensor = tensor.div(255.0);
    
    // Добавление размерности батча
    return tensor.expandDims(0);
  }
  
  private getTopClasses(probabilities: Float32Array, maxResults: number): ClassificationResult[] {
    const probsAndIndices = Array.from(probabilities)
      .map((prob, index) => ({ prob, index }))
      .sort((a, b) => b.prob - a.prob)
      .slice(0, maxResults);
    
    return probsAndIndices.map(({ prob, index }) => ({
      label: this.labels[index],
      probability: prob
    }));
  }
}

interface ClassificationResult {
  label: string;
  probability: number;
}
```

### Пример: Обработка естественного языка

```typescript
class TextProcessor {
  private model: tf.GraphModel;
  private tokenizer: Tokenizer;
  
  constructor() {
    this.tokenizer = new Tokenizer();
  }
  
  async loadModel(modelUrl: string): Promise<void> {
    this.model = await tf.loadGraphModel(modelUrl);
  }
  
  async processText(text: string): Promise<TextAnalysisResult> {
    // Токенизация текста
    const tokens = this.tokenizer.tokenize(text, 128); // Максимальная длина 128 токенов
    
    // Преобразование в тензор
    const inputTensor = tf.tensor2d([tokens], [1, tokens.length]);
    
    // Выполнение инференса
    const prediction = this.model.predict(inputTensor) as tf.Tensor;
    
    // Получение результата
    const result = await prediction.data();
    
    // Освобождение памяти
    inputTensor.dispose();
    prediction.dispose();
    
    return {
      sentiment: this.getSentiment(result),
      confidence: Math.max(...result)
    };
  }
  
  private getSentiment(probabilities: Float32Array): 'positive' | 'negative' | 'neutral' {
    const maxIndex = probabilities.indexOf(Math.max(...probabilities));
    return ['negative', 'neutral', 'positive'][maxIndex] as 'positive' | 'negative' | 'neutral';
  }
}

class Tokenizer {
  private vocab: Map<string, number>;
  
  constructor() {
    // В реальном приложении словарь загружается из файла
    this.vocab = new Map();
    this.vocab.set('[PAD]', 0);
    this.vocab.set('[UNK]', 1);
    this.vocab.set('[CLS]', 2);
    this.vocab.set('[SEP]', 3);
    this.vocab.set('[MASK]', 4);
  }
  
  tokenize(text: string, maxLength: number): number[] {
    // Простая токенизация по пробелам
    const tokens = text.toLowerCase().split(/\s+/);
    const tokenIds = tokens.map(token => this.vocab.get(token) || 1); // 1 для [UNK]
    
    // Добавление специальных токенов
    tokenIds.unshift(2); // [CLS]
    tokenIds.push(3); // [SEP]
    
    // Паддинг или усечение
    if (tokenIds.length > maxLength) {
      return tokenIds.slice(0, maxLength);
    } else {
      return [...tokenIds, ...Array(maxLength - tokenIds.length).fill(0)];
    }
  }
}

interface TextAnalysisResult {
  sentiment: 'positive' | 'negative' | 'neutral';
  confidence: number;
}
```

## Обработка ошибок и отладка

### Обработка ошибок загрузки модели

```typescript
async function loadModelWithErrorHandling(url: string): Promise<tf.GraphModel | null> {
  try {
    const model = await tf.loadGraphModel(url);
    console.log('Модель успешно загружена');
    return model;
  } catch (error) {
    console.error('Ошибка загрузки модели:', error);
    
    // Попытка загрузки резервной модели
    try {
      const backupModel = await tf.loadGraphModel('localstorage://backup-model');
      console.log('Загружена резервная модель');
      return backupModel;
    } catch (backupError) {
      console.error('Ошибка загрузки резервной модели:', backupError);
      return null;
    }
  }
}
```

### Логирование производительности

```typescript
class PerformanceLogger {
  private startTime: number;
  private metrics: PerformanceMetrics;
  
  constructor() {
    this.metrics = {
      loadTime: 0,
      inferenceTime: 0,
      memoryUsage: 0
    };
  }
  
  startTiming(): void {
    this.startTime = performance.now();
  }
  
  endTiming(operation: 'load' | 'inference'): void {
    const endTime = performance.now();
    const duration = endTime - this.startTime;
    
    if (operation === 'load') {
      this.metrics.loadTime = duration;
    } else if (operation === 'inference') {
      this.metrics.inferenceTime = duration;
    }
    
    console.log(`${operation} took ${duration.toFixed(2)} ms`);
  }
  
  getMetrics(): PerformanceMetrics {
    return { ...this.metrics };
  }
}

interface PerformanceMetrics {
  loadTime: number; // в миллисекундах
  inferenceTime: number; // в миллисекундах
  memoryUsage: number; // в байтах
}
```

## Заключение

Запуск моделей машинного обучения в браузере открывает новые возможности для создания интерактивных и персонализированных веб-приложений. TypeScript обеспечивает строгую типизацию, что делает разработку более надежной и предсказуемой, особенно при работе со сложными структурами данных, какими являются тензоры.

## См. также

- [[TensorFlow-js]]
- [[ONNX-js]]
- [[Инференс]]
- [[Обучение-в-браузере]]
- [[Оптимизация-моделей-для-браузера]]